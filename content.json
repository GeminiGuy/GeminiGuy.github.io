{"meta":{"title":"隔壁老王的Blog","subtitle":null,"description":"嘘，要发车了","author":"Gemini","url":"https://geminiguy.github.io"},"pages":[{"title":"categories","date":"2017-01-14T09:04:41.000Z","updated":"2017-01-14T09:12:51.000Z","comments":false,"path":"categories/index.html","permalink":"https://geminiguy.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-01-14T05:54:18.000Z","updated":"2017-01-14T06:02:54.000Z","comments":false,"path":"tags/index.html","permalink":"https://geminiguy.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"震惊，Kafka出大事儿了","slug":"kafka-talk","date":"2017-03-04T16:00:00.000Z","updated":"2017-03-06T09:14:04.000Z","comments":true,"path":"2017/03/05/kafka-talk/","link":"","permalink":"https://geminiguy.github.io/2017/03/05/kafka-talk/","excerpt":"序使用Kafka也有几个月的时间，然而期间出现了一件怪事儿，背后隐藏着怎样的惊天秘密呢？看完以后倒吸一口凉气，令人不解，男默女泪~~ （ps：uc体实在编不下去了，逃","text":"序使用Kafka也有几个月的时间，然而期间出现了一件怪事儿，背后隐藏着怎样的惊天秘密呢？看完以后倒吸一口凉气，令人不解，男默女泪~~ （ps：uc体实在编不下去了，逃 遇到的问题及分析Kafka使用过程中出现过一个比较严重的问题，每天都会有若干个的broker不定时间的触发SessionExpirationListener，也就是broker与zk的session出现超时，默认为6s，少则十几次，多则二十多次。broker与zookeeper的会话超时有多方面的原因，例如broker gc、主机cpu、memeory、网络资源不足、zk端hang on等等。下面一一进行排查。 zookeeper.session.timeout.ms默认为6000(6s)，出现session timeout又重新和zk建立了session时，SessionExpireListener的handleNewSession被触发，相当于重新在/broker/ids/下注册broker结点信息，接着触发BrokerChangeListener的handleChildChange方法。从zk的/broker/ids结点因超时被删除到重新建立这个过程，90%的情况都在1个ticktime（2s）搞定，也就是说超时后2s又回来了。ok，接着我就去broker的server.properties中把zookeeper.session.timeout.ms=12000。 然并卵，情况并没有缓解多少。绝大部分情况还是2s后会话又重新建立了，囧，玩我呢。之后我就去查究竟什么原因导致的这个会话超时。针对这个问题，很多人会说查gc啊，好，查gc，把出问题时间段的gc日志拉出来，对所有的gc时间排序（管它的是young gc还是full gc，管它是stw以及可以和用户线程并发执行的），排除这个原因，囧。 broker端cpu（12核机器占满6核数，），memory和网络资源都没问题。zk端这些资源更充足了，也不是这个原因。而且几台broker的Byte in和Byte out都不算高。 zk hang on，排除。 怎么破，只能试着再提升下超时时间。 zookeeper.connection.timeout.ms=12000zookeeper.session.timeout.ms=20000 改完这个配置，居然五天内只出现了一次zk expire的情况，真是醉了。究竟是实际运维Kafka过程中遇到“真”的问题，还是玄学似的有这么一个阈值的限制呢？还是不得而知，ps，信息系统部专门管理Kafka的参数设置好像也是设置的20s。 Final这个问题暂时作为一个未解之谜吧，或许有一天就突然发现了呢。这周六做的农家小炒肉真是失败，关键是小区门口超市没有猪后腿肉了，以后想做肉菜还得去趟大超市采购。周末跑步打卡贴一下，不然如何对得起这个闲聊tag，闪人~~","categories":[{"name":"技术","slug":"技术","permalink":"https://geminiguy.github.io/categories/技术/"}],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/tags/闲聊/"},{"name":"Kafka","slug":"Kafka","permalink":"https://geminiguy.github.io/tags/Kafka/"}]},{"title":"17年，狼叔再见","slug":"jinganglang3-Logan","date":"2017-03-03T16:00:00.000Z","updated":"2017-03-05T07:04:54.000Z","comments":true,"path":"2017/03/04/jinganglang3-Logan/","link":"","permalink":"https://geminiguy.github.io/2017/03/04/jinganglang3-Logan/","excerpt":"英雄迟暮，X时代的终结","text":"英雄迟暮，X时代的终结 周五下了班，和组里的小伙伴骑车从软件园20分钟赶到上地那边的影院，看了这部《金刚狼3：殊死一战》，说到“殊死”一词，其实这部影片中的战斗戏份相比以往少了许多，一是国内引进这部R级大片的时候已删了14分钟的片段（回头一定回刷完整版），二来英雄老矣。这部影片中的X战警成员只剩下金刚狼和X教授，X教授患上了阿尔茨海默病，发作时无法控制自己的能力，在墨西哥边境隐居，饱受病痛折磨，而金刚狼身边的战友以及女友们都已不在（真是克女友命），整日抑郁消沉，饮酒度日，超能力也下降了很多。 有一天，一位陌生女子让罗根送一个叫劳拉的女孩去加拿大边境，Logan从一开始的拒绝到逐步了解背后的真相，一路带着自己的“女儿”劳拉，躲避黑暗势力的追杀，期间X教授也挂掉了，Logan在和变异“金刚狼”玩命打斗中也光荣牺牲。一群小屁孩得以脱险（那位小黑胖子莫名喜感啊），整部电影多了些温情，颇有点《这个杀手不太冷》的意思。片中劳拉其实是由罗根的血清被克隆出来的小金刚狼（在《天启》最后彩蛋中有提到血清一事）。 虽然X战警和金刚狼的几部电影都有看过，但是对于休·杰克曼这位演员也是各种科普后才算了解。17年来为了这一个角色的坚持，从未间断过身材的保持，X战警中的演员可能就金刚狼这个角色从未换过演员吧，值得敬佩的好演员，也算是一个时代的经典。以下几张图片转自豆瓣的一篇影评，都是回忆啊，推荐一下。生活和时间才是永远的对手，超级英雄也无力对抗 整个观影过程中，时不时地都会去看下手机上的时间，总想让时间过得慢一些，电影不要这么快结束，然而待字幕结束，并没有等来期待的彩蛋，幕黑灯亮，人们纷纷散场，X英雄们，再见，Logan，再见了……","categories":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/categories/闲聊/"}],"tags":[{"name":"电影","slug":"电影","permalink":"https://geminiguy.github.io/tags/电影/"},{"name":"金刚狼","slug":"金刚狼","permalink":"https://geminiguy.github.io/tags/金刚狼/"}]},{"title":"Kafka Offset倒回和数据丢失？","slug":"kafka-offset-rewinds-offset-lost","date":"2017-02-27T16:00:00.000Z","updated":"2017-03-05T02:14:15.000Z","comments":true,"path":"2017/02/28/kafka-offset-rewinds-offset-lost/","link":"","permalink":"https://geminiguy.github.io/2017/02/28/kafka-offset-rewinds-offset-lost/","excerpt":"序言 Kafka Offset Rewinds是什么？Kafka数据丢失又由哪些原因造成？如果读者对这些问题了如指掌，那么大神走好不送，这篇文章可以不用浪费时间了。本文首先对我们业务生产环境中遇到的offset rewinds问题做一个详尽分析，接着引出kafka数据丢失的各种情况。OK，废话少说，戳我，🔽阅读全文。","text":"序言 Kafka Offset Rewinds是什么？Kafka数据丢失又由哪些原因造成？如果读者对这些问题了如指掌，那么大神走好不送，这篇文章可以不用浪费时间了。本文首先对我们业务生产环境中遇到的offset rewinds问题做一个详尽分析，接着引出kafka数据丢失的各种情况。OK，废话少说，戳我，🔽阅读全文。 Kafka Offset RewindsOffset Rewinds概念 Kafka的某个group的某个consumer进程（线程）由Coordinator分配了消费任务去fetch某个分区的数据后，会根据该group提交的offset去决定从分区的哪个偏移位置去开始消费。当然，如果这是一个新的group还没有提交过offset，或者之前提交的offset发生了越界错误，比如offset对应的位移的数据由于已过期日志已被删除，再比如，你想poll的那个位移处的数据还没有写入leader（wtf？这是有可能的，正是本文现象所讨论的，别急，往下看）。此时就会根据你的consumer实例初始化时设置的auto.offset.reset参数决定处理方式。设置为earliest，从leader能获取的最小的位移偏移量开始拉取数据，造成大量重复消费。latest则自动初始化为最新的位移偏移量处poll数据进行消费，存在丢失数据的可能性。而本文的offset rewinds主要是指offset位移偏移量倒回到最早的一条数据开始消费这种现象。 现象review及排查 先来看一下这个问题是如何被监控到的，我们的同学对于wb_userdata_ffk03新开了个group，将消费到的数据写入influxdb并基于Grafana进行了监控，可以看到某天晚上19：00左右的时候消费的数据量比之前突增了五倍，同时Burrow也发出了lag堆积报警，查看Kafka-manager也可以看到几个堆积的分区在同一个broker上面。种种现象说明了我们的group发生了offset rewinds，从头开始消费。 以topic：wb_userdata_ffk03，partition：19，AR：[2,3]，ISR：[2,3], leader：2为例。去相应的broker上面进行日志排查，看看7点左右到底发生了什么。broker 2的controller.log显示如下： broker 1的controller.log 从上面两张截图可以看到broker 2在18:58:54时重新加入了，说明之前该结点被删过额，那第二张截图为何没有打印deleted brokers呢，只有一个原因，broker 2此时还是controller，囧啊。不过没有关系，下面这张截图broker 2 controller的日志明确验证了此时broker 2 session timeout，broker failure喽。 到目前为止，我们能够确信这个时间点，这个分区的leader 2确实failure了，但是为何会出现offset rewinds呢？悲剧继续上演…… 这张截图是broker 2的server.log，可以看到这时候replica 3从ISR中被踢出去了，此时ISR中就只有2了，接着leader 2又发生了宕机😶。 关于这个ISR状态的变化我再多说一点。什么情况下一个replica会被从ISR中踢出去呢？先大体看一下maybeShrinkIsr和getOutOfSyncReplicas两个函数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 def maybeShrinkIsr(replicaMaxLagTimeMs: Long) &#123; val leaderHWIncremented = inWriteLock(leaderIsrUpdateLock) &#123; leaderReplicaIfLocal() match &#123; case Some(leaderReplica) =&gt; val outOfSyncReplicas = getOutOfSyncReplicas(leaderReplica, replicaMaxLagTimeMs) if(outOfSyncReplicas.size &gt; 0) &#123; val newInSyncReplicas = inSyncReplicas -- outOfSyncReplicas assert(newInSyncReplicas.size &gt; 0) info(\"Shrinking ISR for partition [%s,%d] from %s to %s\".format(topic, partitionId,inSyncReplicas.map(_.brokerId).mkString(\",\"),newInSyncReplicas.map(_.brokerId).mkString(\",\"))) // update ISR in zk and in cache updateIsr(newInSyncReplicas) // we may need to increment high watermark since ISR could be down to 1 replicaManager.isrShrinkRate.mark() maybeIncrementLeaderHW(leaderReplica) &#125; else &#123; false &#125; case None =&gt; false // do nothing if no longer leader &#125; &#125; // some delayed operations may be unblocked after HW changed if (leaderHWIncremented) tryCompleteDelayedRequests()&#125;def getOutOfSyncReplicas(leaderReplica: Replica, maxLagMs: Long): Set[Replica] = &#123; /** * there are two cases that will be handled here - * 1. Stuck followers: If the leo of the replica hasn't been updated for maxLagMs ms, * the follower is stuck and should be removed from the ISR * 2. Slow followers: If the replica has not read up to the leo within the last maxLagMs ms, * then the follower is lagging and should be removed from the ISR * Both these cases are handled by checking the lastCaughtUpTimeMs which represents * the last time when the replica was fully caught up. If either of the above conditions * is violated, that replica is considered to be out of sync * **/ val leaderLogEndOffset = leaderReplica.logEndOffset val candidateReplicas = inSyncReplicas - leaderReplica val laggingReplicas = candidateReplicas.filter(r =&gt; (time.milliseconds - r.lastCaughtUpTimeMs) &gt; maxLagMs) if(laggingReplicas.size &gt; 0) debug(\"Lagging replicas for partition %s are %s\".format(TopicAndPartition(topic, partitionId), laggingReplicas.map(_.brokerId).mkString(\",\"))) laggingReplicas&#125; 在getOutOfSyncReplicas函数的注释中把replica剔除ISR的情况说的比较清楚。 1.这个replica fetch的进程stuck住了，该replica的leo超过maxLagMs没有更新了。 2. follower的拷贝速度远远跟不上leader的写入速度，已经持续落后了maxLagMs。 这两种情况都可以用lastCaughtUpTimeMs来计时，这个参数代表了这个replica上一次完全追上leader的时间戳。 接着我们再来看一下ISR中只剩下2，而2又宕机了，肿么办，其实此刻该分区还是可以用的，因为默认开启了unclean.leader.election.enable这个功能，允许进行unclean选举，未能及时同步的replica 3被选举为leader，可以看如下日志。发生unclean选举的危害不只在offset会发生倒退，而且未能同步到replica的数据基本上就丢失了。那么把这个功能关了不就ok了吗？自古美事两难全，我们在下一节来细说这个Unclean leader election。 其他问题 其实造成offset rewinds的问题是并不局限于unclean leader election，剖析Linkedln遭遇的Kafka“危机故障”这篇文章中也介绍了LinkedIn之前遇到的一些Bug级别（目前已修复）的offset rewinds，以供参考。 Kafka数据丢失？Unclean leader election 是否允许unclean选举其实也是可用性和数据一致性的trade-off问题。官方文档针对unclean选举有这么一段，我结合自己的理解来翻译一下。 Unclean leader election: What if they all die?Note that Kafka’s guarantee with respect to data loss is predicated on at least one replica remaining in sync. If all the nodes replicating a partition die, this guarantee no longer holds.However a practical system needs to do something reasonable when all the replicas die. If you are unlucky enough to have this occur, it is important to consider what will happen. There are two behaviors that could be implemented: Wait for a replica in the ISR to come back to life and choose this replica as the leader (hopefully it still has all its data). Choose the first replica (not necessarily in the ISR) that comes back to life as the leader. This is a simple tradeoff between availability and consistency. If we wait for replicas in the ISR, then we will remain unavailable as long as those replicas are down. If such replicas were destroyed or their data was lost, then we are permanently down. If, on the other hand, a non-in-sync replica comes back to life and we allow it to become leader, then its log becomes the source of truth even though it is not guaranteed to have every committed message. By default Kafka chooses the second strategy and favor choosing a potentially inconsistent replica when all replicas in the ISR are dead. This behavior can be disabled using configuration property unclean.leader.election.enable, to support use cases where downtime is preferable to inconsistency. This dilemma is not specific to Kafka. It exists in any quorum-based scheme. For example in a majority voting scheme, if a majority of servers suffer a permanent failure, then you must either choose to lose 100% of your data or violate consistency by taking what remains on an existing server as your new source of truth. 需要注意的是，kafka对于数据丢失的保障是基于ISR中至少一个副本在保持同步。如果该分区上所有的副本结点都挂了，那这保证就不再成立了。然后实际系统需要对所有replica die的情况进行处理。如果你人品不好遇到了这种情况，需要考虑以下两种处理方式，就变得至关重要了： 等着ISR中的一个副本活过来，并选举它为leader 选择第一个活过来的副本（不一定在ISR中）作为leader 其实这就是针对可用性和一致性的简单权衡了。如果选择等待ISR中的一个副本，那么只要ISR中的replica一直down，ok，那么这个分区就不可用，如果这些replica损坏或者数据丢失（管它什么原因），那就是永久的不可用了。另一个方面，如果我们选择了一个不是ISR中的replica作为leader，那它的log将成为数据源，即使它的log中并不能够保证拥有每条已经被commited的消息。目前我们用的版本中默认是选择了第二种处理方式，如果ISR中的所有replica挂了就选择了一个潜在数据不一致的replica作为leader。如果我们对于数据一致性的要求比宕机可用性的要求更高，就可以通过unclean.leader.election.enable=false禁用掉，这个可以细化到某个topic级别。这里我多说一句什么是committed消息，如果一条消息被ISR中所有的replica记录到log中，那么这条消息就被认为是committed的，对于consumer端而言，只有被committed的消息才能被看到，而High Watermark就是最新的的一条committed message的位移。 这种窘境也不只Kafka存在，任何基于quorum的方案中都会存在。例如在多数投票的方案中，如果多数的服务器将可能永久不可用，你是选择100%丢失数据呢？还是违反一致性，用幸存的服务器上还有的数据作为新的数据源？ Producer端数据丢失？ 既然在未同步的replica中选举leader会发生数据丢失，那么从ISR中进行leader选举是否就100%保证数据完整了呢？Native~~我们再来看这种情况： ACK=1，ISR=(1,2,3), leader=1 replica 1作为leader已经确认了producer的一些records写入local log，并成功返回给了producer响应。此时leader failure，且follower 2和3还没来得及复制这些records。重新选举，ISR=(2,3)，其中2当选leader，makeLeader的过程中HW还是保持了之前的旧值。接着1活过来了，成为follower，截断自己的log至HW，replica 1的HW至leo的数据也就被抛弃了，因此之前写入replica 1但还未同步到replica 2的数据也就彻底丢失了。replica 1没有活过来，当然数据也丢失了。 解决办法是，producer端设置ACK=all(-1)，broker端针对具体的topic设置min.insync.replicas=2，这样producer只有等待ISR中至少两个replica已经确认写入了这条消息，才会给producer返回正确响应。如果该条件无法满足，则触发异常。当然了，producer端这么设置之后，数据完整性明显高了许多，换来的必然是吞吐量的下降，哎，这又是一个trade-off的问题啊。 总结 本文针对unclean leader选举造成的offset rewinds情况进行了实际的分析，进而引出了kafka丢失数据的各种情况。However，针对不同的业务场景进行可用性与数据一致性的权衡、吞吐量与数据完整性的权衡，是非常重要的。最重要的还是保证Kafka集群的的稳定和健康。","categories":[{"name":"技术","slug":"技术","permalink":"https://geminiguy.github.io/categories/技术/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://geminiguy.github.io/tags/Kafka/"},{"name":"数据一致性","slug":"数据一致性","permalink":"https://geminiguy.github.io/tags/数据一致性/"},{"name":"高可用性","slug":"高可用性","permalink":"https://geminiguy.github.io/tags/高可用性/"}]},{"title":"周末瞎扯淡","slug":"周末瞎扯淡","date":"2017-02-25T16:00:00.000Z","updated":"2017-02-28T12:34:57.000Z","comments":true,"path":"2017/02/26/周末瞎扯淡/","link":"","permalink":"https://geminiguy.github.io/2017/02/26/周末瞎扯淡/","excerpt":"序言周末瞎扯淡，记个流水账。","text":"序言周末瞎扯淡，记个流水账。 老王私房菜每周继续坚持做一道新菜，周六吃完烤肉，周日吃点素吧。西葫芦炒西红柿，味道还是很不错的。Ps：md，想试着做炒面，上周那种湿面差点又把我的炒锅给毁了，日了🐩了，果断弃之~~ 意外发现周六早晨躺床上被微博的一个游戏视频广告吸引了，《梦幻西游无双版》，下下来玩了一下，没想到历经了13年的回合制游戏还是出了即时战略版本啊，容我怀个旧~~ 还记得当年的海底沉船么，最后的boss那里是否还能遇到多年后变成大侠的自己呢？已然记不太清楚了。。。。。。 健身打卡 周日跑步打个卡，逐渐加量吧，下一周争取能跑10的速度，再加个1KM，恩，每周坚持至少两次跑步。","categories":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/categories/闲聊/"}],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/tags/闲聊/"}]},{"title":"Kafka Controller填坑","slug":"kafka-controller-makeLeader&Follower","date":"2017-02-18T16:00:00.000Z","updated":"2017-02-19T08:54:06.000Z","comments":true,"path":"2017/02/19/kafka-controller-makeLeader&Follower/","link":"","permalink":"https://geminiguy.github.io/2017/02/19/kafka-controller-makeLeader&Follower/","excerpt":"序言 阳光明美日，正是填坑时 之前有一篇Kafka Controller的文章中，对于RelicaManager的makeLeaders、makeFollowers方法具体实现逻辑留了一个坑，时隔好久，回来把这个坑补上，其中参考了0.10版本的scala源码以及两篇博客，最后参考文献中会有注明。","text":"序言 阳光明美日，正是填坑时 之前有一篇Kafka Controller的文章中，对于RelicaManager的makeLeaders、makeFollowers方法具体实现逻辑留了一个坑，时隔好久，回来把这个坑补上，其中参考了0.10版本的scala源码以及两篇博客，最后参考文献中会有注明。 ReplicaManager.makeLeaders 首先对于接收到makeLeaders请求的broker来说，对于每一个本地的replica将成为leader的partition，移除该partition的Fetcher，因为如果本地replica不再是follower，就不需要从leader拉取消息了。 对每个partition调用partition.makeLeader方法： 更新allReplica列表，对于新增的replica要创建log、 初始化highWater等等。对于当前分配的replica不在allReplicas中，则需要从assignedReplicas中删除。 更新Partition对象的ISR，controllerEpoch，leaderEpoch，zkVersion等信息。 如果本地replica之前不是leader，成为了leader，需要更新leader replica的highWater。 把所有remote replica的leo重置了成UnknownOffsetMetadata（-1），在maybeIncrementLeaderHW中会取所有replica中最小的leo，如果除leader外有其他replica，因为刚被重置过，最小leo一定是-1，-1一定小于当前的hw，所以hw其实不会被increment。只有当isr中只有leader时，那hw会被increment到leader.leo。 ReplicaManager.makeFollowers 针对本地每一个replica将成为follower的分区，调用partition.makeFollower方法。 partition.makeFollower中，更新partition的controllerEpoch、ISR（初始化为空）、leaderEpoch、zkVersion等信息。 更新allReplica列表，对于新增的replica要创建log、 初始化highWater等等。对于当前分配的replica不在allReplicas中，则需要从assignedReplicas中删除。 如果partition的leader发生变化，返回true，partition加入partitionsToMakeFollower set中，否则，返回false。 针对partitionsToMakeFollower，移除旧的Fetcher。 如果leader发生了变化，之前同步的数据和新的leader可能不一致，也有可能之前作为leader的leo大于现在leader的leo，因此需要把log截断至highWater。 如果当前broker没有在shuttingDown的话，添加新的leader的Fetcher __consumer_offsets的特殊情况 partition中topic为__consumer_offsets的特殊情况处理，对于新成为的leader，调用coordinator.handleGroupImmigration方法，进而调用groupManager.loadGroupsForPartition方法，将从log中把属于当前分区的Offset项恢复到OffsetCache中。对于新成为的followers，coordinator.handleGroupEmigration方法中进而调用groupManager.removeGroupsForPartition方法，清除之前的属于该partition的消费者组提交的offset缓存。 参考文献 Kafka源码阅读-KafkaController(2) Apache Kafka源码分析 - KafkaApis","categories":[{"name":"技术","slug":"技术","permalink":"https://geminiguy.github.io/categories/技术/"}],"tags":[{"name":"Kafka Controller","slug":"Kafka-Controller","permalink":"https://geminiguy.github.io/tags/Kafka-Controller/"}]},{"title":"周六杂记—壹贰叁","slug":"Note-20170218","date":"2017-02-17T16:00:00.000Z","updated":"2017-02-18T16:14:51.000Z","comments":true,"path":"2017/02/18/Note-20170218/","link":"","permalink":"https://geminiguy.github.io/2017/02/18/Note-20170218/","excerpt":"杂记壹 回顾这一周，好像都在应付各种小项目开发，粉条2017年改版大项目启动，设计评审会加各种对接口格式又是两天的时间。用来学习基础jvm知识的时间大大被压榨，买的《人类简史》和《未来简史》也沉睡了好几天。However，最重要的是，我的锅也沉睡许久，是时候唤醒它了~~ 之前设想的是每周都学做一道新菜，不仅是因为我司食堂太难吃，也是让自己的码农生活不要过得太屌丝吧，多一些正能量，或许就成了程序猿界的“厨神”了呢？😁周六早上反而睡不久了，于是乎起床买菜，在超市里看到了新鲜的湿面，这是个悲剧的前戏……","text":"杂记壹 回顾这一周，好像都在应付各种小项目开发，粉条2017年改版大项目启动，设计评审会加各种对接口格式又是两天的时间。用来学习基础jvm知识的时间大大被压榨，买的《人类简史》和《未来简史》也沉睡了好几天。However，最重要的是，我的锅也沉睡许久，是时候唤醒它了~~ 之前设想的是每周都学做一道新菜，不仅是因为我司食堂太难吃，也是让自己的码农生活不要过得太屌丝吧，多一些正能量，或许就成了程序猿界的“厨神”了呢？😁周六早上反而睡不久了，于是乎起床买菜，在超市里看到了新鲜的湿面，这是个悲剧的前戏…… 人生不只有苟且的工作，还有眼前的凉拌花生米和辣子鸡 杂记贰 下午看了会《未来简史》，睡了一觉醒来六点多了。晚饭吃点啥呢？凉拌花生米没有吃完，干脆下早上买的湿面吧，悲剧开始了…… 内心OS：好想拿刀砍了这湿面 杂记叁 晚上一个也住在附近的师弟要过来找我谈心，我的煮面小奶锅毁了，我也要出去散散心，😶，出去溜了一圈，果然有收获，见图。 一辆废弃的加长林肯，孤独的守候在五环外的马路边，“辽”字车牌隐约可见。这位东北大哥曾经的辉煌，你读懂了吗？ 杂记终最后以《乘风破浪》里的一句经典台词作为这篇毫无逻辑的杂记文章的结尾吧。 我的梦想，歌舞厅里只唱歌，桑拿馆里就洗澡！ 还有一首非常好听的歌曲推荐，500 Miles，晚安，好梦~~","categories":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/categories/闲聊/"}],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/tags/闲聊/"},{"name":"美食","slug":"美食","permalink":"https://geminiguy.github.io/tags/美食/"}]},{"title":"Ckestrel框架浅析","slug":"ckestrel框架浅析","date":"2017-02-11T16:00:00.000Z","updated":"2017-02-12T07:40:58.000Z","comments":true,"path":"2017/02/12/ckestrel框架浅析/","link":"","permalink":"https://geminiguy.github.io/2017/02/12/ckestrel框架浅析/","excerpt":"概述 Kestrel是一个利用Scala语言编写的轻量级消息队列，由Twitter团队开源，其支持三种协议：memcache、thrift、text。Kestrel具有高性能、代码轻量级、持久存储（记录读写日志到journal）、可靠性（支持可靠获取）等优点。而本文所要说的Ckestrel是Kestrel的C++版本，由团队的老前辈改版而成，采用的协议是memcached文本协议。由于吞吐量、稳定性、代码维护性等等原因满足不了业务需求，因此逐步会被Kafka取而代之。这篇文章是我15年刚入职那会调研学习这个框架的源码所写的wiki，现照搬到我的博客上面。本文将对Ckestrel的线程模型及状态机、持久化日志和可靠性读取机制等方面做相关分析。","text":"概述 Kestrel是一个利用Scala语言编写的轻量级消息队列，由Twitter团队开源，其支持三种协议：memcache、thrift、text。Kestrel具有高性能、代码轻量级、持久存储（记录读写日志到journal）、可靠性（支持可靠获取）等优点。而本文所要说的Ckestrel是Kestrel的C++版本，由团队的老前辈改版而成，采用的协议是memcached文本协议。由于吞吐量、稳定性、代码维护性等等原因满足不了业务需求，因此逐步会被Kafka取而代之。这篇文章是我15年刚入职那会调研学习这个框架的源码所写的wiki，现照搬到我的博客上面。本文将对Ckestrel的线程模型及状态机、持久化日志和可靠性读取机制等方面做相关分析。 CKestrel线程模型及状态机线程模型 Ckestrel采用了memcached的线程模型来处理网络连接，而memcached使用libevent实现异步服务器，采用主线程和worker线程，主线程负责监听网络连接，并且accept连接。当监听到连接时，accept连接成功后，把相应的client fd丢给其中一个worker线程。worker线程接收主线程丢过来的client fd，加入到自己的epoll监听队列，负责处理该连接的读写事件。memcached的线程模型图如下所示： 主线程通过evnet_init()为自己分配一个event_base，用于监听连接，即listen fd。 主线程创建n个worker线程，同时每个worker线程也分配了独立的event_base。每个worker线程通过管道方式与主线程进行通信，调用pipe函数，产生两个fd，一个是管道写入fd（notify_send_fd），一个是管道读取fd（notify_receive_fd）。worker线程把管道读取fd（notify_receive_fd）加到自己的event_base，监听管道读取fd的可读事件，即当主线程往某个线程的管道写入fd写数据时，触发事件。 主线程监听到有一个连接到达时，accept连接，产生一个client fd，然后选择一个worker线程，把这个client fd包装成一个CQ_ITEM对象（其中不仅有client fd参数，还包括init_state、event_flags、read_buffer_size等参数）然后压到worker线程的CQ_ITEM队列里面去（每个worker线程有一个CQ_ITEM队列），同时主线程往选中的worker线程的管道写入fd中写入一个字符“c”（Ckestrel中写入””，用来触发worker线程）。 某个worker线程监听到自己的管道读取fd可读，触发事件处理函数thread_libevent_process，从CQ_ITEM队列中取出CQ_ITEM对象，调用conn_new函数把此client fd加入到自己的event_base中，从此负责该连接的读写工作。 状态机 主线程和worker线程都调用conn_new函数进行事件监听，有事件发生时调用event_handler函数，最终执行driver_machine函数。状态机drive_machine函数是worker线程处理网络请求业务的逻辑核心。while循环中包含switch case，根据连接对象conn的当前连接状态state进入不同的case，每个case可能会改变conn对象的连接状态，进而被分发到合适的case上进行处理，最终由stop=true的case分支退出while循环。详细的解析请参考Memcached源码分析之请求处理。 Ckestrel持久化日志 Ckestrel日志文件是唯一在硬盘存储队列内容的方式，日志文件中顺序记录每个针对相应队列的添加和删除操作。每种操作有对应的flag来记录日志类型，flag总共有以下几种：CMD_ADD、CMD_ADDX、CMD_ADD_XID、CMD_REMOVE、CMD_REMOVE_TENTATIVE、CMD_SAVE_XID、CMD_UNREMOVE、CMD_CONFIRM_REMOVE。其中CMD_ADDX和CMD_ADDXID操作会利用自定义的pack压缩方式将某条队列消息的length、xid、addTime、expiry、data等信息写入日志文件中。Ckestrel服务器启动时，对每个队列的日志文件执行replayJournal操作，重新建立内存中的队列以便客户端访问。这种方式保证了即使服务器崩溃，也能根据每个队列的日志文件重建内存中的队列消息。 Ckestrel框架在对journal处理上与目前scala 2.4.1版本上有些区别。Journal.cc中实现了roll机制对日志文件进行压缩。在PersistentQueue.cc中的add方法中： 1234567891011if (keepJournal_ &amp;&amp; !journal_-&gt;inReadBehind()) &#123; if (journal_-&gt;size() &gt; maxJournalSize_ * maxJournalOverflow_ &amp;&amp; queueSize_ &lt; maxJournalSize_) &#123; slog_write(LL_NOTICE, \"Rolling journal file for '%s' (qsize=%d)\", name_.c_str(), queueSize_); deque&lt;QItem *&gt; q = openTransactionQItems(); journal_-&gt;roll(xidCounter_, q, queue_); &#125; if (queueSize_ &gt;= maxMemorySize_) &#123; slog_write(LL_NOTICE, \"Dropping to read-behind for queue '%s' (%lu bytes)\", name_.c_str(), queueSize_); journal_-&gt;startReadBehind(); &#125; &#125; 利用kestrel.conf配置文件设置 maxJournalSize = 16M，maxJournalOverflow = 10，maxMemorySize = 128M。初始向队列写入数据时，journal不会进入ReadBehind模式。当日志文件大小大于maxJournalSize * maxJournalOverflow并且队列大小小于maxJournalSize时，journal进行roll操作，重新建立日志文件，将内存中的队列消息add进journal_日志中，其中利用pack编码方式，opcode=CMD_ADDX。同样将openTransactionQItems中未完成的事务记录在对应日志当中。 当队列大小大于等于maxMemorySize_时，启动ReadBehind模式，后面写入队列的消息将会存储在日志文件中，每当从内存中remove掉消息的时都会尝试从日志文件中读取相关队列消息再pushback到内存队列中，这种状态一直持续到reader和writer_指针重合，即在ReadBehind模式下add进日志文件的消息均被处理完毕，退出ReadBehind模式。 另外在PersistentQueue.cc中remove方法中，当if (queueLength == 0 &amp;&amp; journal -&gt;size() &gt;= maxJournalSize_)时，也会对日志文件进行roll操作。 可靠性读取 默认的GET并没有加入可靠性读取选项，从队列中获取消息后，server端就将该消息从队列中移除，如果客户端在处理这个消息的时候异常崩溃或者在接收消息时连接断开，则该条队列数据就会永久丢失，而之前出现的RIN数据丢失问题则出现在这里。这种默认的方式是不安全的，因此Kestrel提供了可靠性读取机制，在GET命令中加入/open和/close选项。官方文档对/open和/close的描述如下： /openTentatively remove an item from the queue. The item is returned as usual but is also set aside in case the client disappears before sending a “close” request. /closeClose any existing open read. 当在消费机客户端GET命令中使用/open时，kestrel服务器将这个消息从队列暂时移除并正常发送给消费机客户端，同时在openTransactions这个map容器中备份该队列数据，如果这时候客户端崩溃或者断开连接，从openTransactions中根据xid键取出该队列数据，重新放入内存队列头部，因此当客户端重新连接后就可以获取到该队列消息。每个连接的client只能有一个正在执行的可靠获取，再次发送带有/open选项的GET命令server返回空（同一个连接直接发送GET命令也会返回空）。当消费机客户端收到该队列数据时，再次发送带/close选项的GET命令，server将会confirmRemove该队列数据，从openTransactions_容器中删除这条队列数据，并在日志文件中记录CMD_CONFIRM_REMOVE。 具体分析发送完带/open选项的GET命令后，消费机与队列机服务器断开连接，则进入Ckestrel.cc中的conn_close函数，执行qc-&gt;unremove操作。 12345678static void conn_close(conn *c)&#123; if (c-&gt;xid) &#123; if (qc-&gt;unremove(std::string(c-&gt;xkey, c-&gt;xnkey), c-&gt;xid) == false) &#123; slog_write(LL_WARNING, \"Unremove non-existent transaction\"); &#125; c-&gt;xid = 0; &#125;&#125; 最终进入PersistentQueue.cc的doUnremove函数，在openTransactions_容器中根据上一条队列消息的xid找到该item，再pushfront到内存队列头部，在openTransactions容器中删除该队列消息。客户端重新连接到服务器后，就可以从服务器内存队列中取到该条队列消息，这就是kestrel的可靠读取机制的实现。 123456789101112bool PersistentQueue::doUnremove(int xid) &#123; map&lt;int, QItem*&gt;::iterator it = openTransactions_.find(xid); if (it != openTransactions_.end()) &#123; queueLength_ += 1; queueSize_ += it-&gt;second-&gt;getLength(); queue_.push_front(it-&gt;second); memoryBytes_ += it-&gt;second-&gt;getLength(); openTransactions_.erase(it); return true; &#125; return false;&#125; 总结 本文从Kestrel的线程模型、状态机、持久化日志、可靠性读取四个方面进行了简单的分析。虽然Kestrel已成为历史，但是其中memcached网络模型、libevent异步事件处理库等知识点还是很值得去学习和思考的。另推荐一篇对memcached源码分析写的非常不错的系列博客。Memcached源码分析","categories":[{"name":"技术","slug":"技术","permalink":"https://geminiguy.github.io/categories/技术/"}],"tags":[{"name":"Kestrel","slug":"Kestrel","permalink":"https://geminiguy.github.io/tags/Kestrel/"},{"name":"memcache","slug":"memcache","permalink":"https://geminiguy.github.io/tags/memcache/"},{"name":"libevent","slug":"libevent","permalink":"https://geminiguy.github.io/tags/libevent/"},{"name":"分布式消息","slug":"分布式消息","permalink":"https://geminiguy.github.io/tags/分布式消息/"}]},{"title":"我眼中的2016年电影之最","slug":"2016-movie","date":"2017-02-05T03:33:43.000Z","updated":"2017-02-11T09:05:35.000Z","comments":true,"path":"2017/02/05/2016-movie/","link":"","permalink":"https://geminiguy.github.io/2017/02/05/2016-movie/","excerpt":"前言 初九，北京，阳光灿烂的日子。老天赏了个好脸色，仿佛在召唤村里的码农明天赶紧回来开工。隔壁老王平时比较喜欢赏片（别想歪2333），因此想趁着新的一年开工之前，再来回顾一下2016年那些经典的电影。 There are a thousand Hamlets in a thousand people’s eyes. —William Shakespeare 老莎说过，一千个人眼里就有一千个哈姆雷特。每个人都有自己喜欢的电影类型，这两年豆瓣上不乏“哈韩党”、“文艺装逼党”，高分的电影未必符合大众的审美，不一定好看。当然低分的国产电影，您也无需恼火，就像春节档上映的《西游伏妖篇》，特效还算不错，笑点还算凑合，虽然剧情烂了点，但是春节带着大朋友、小朋友们一起看看这种无厘头电影，乐呵乐呵，也是一种不错的体验，何况星爷是一位好的演员，但是从来也没有被承认过是一位好的导演和编剧。看到微博、豆瓣上面对这个片的好坏争得面红耳赤，真没这个必要。目前国内导演不是拍不出好的电影，而是意识形态所决定的，也不能全怨光腚总局，这个知乎好像有过讨论。况且你造每年美帝和棒子国也生产出很多烂片么？好片毕竟是少数。大家都这么忙，选自己喜欢的电影去消磨时间就OK啦，何必咸吃萝卜淡操心，人家吃你家一粒米啦？呵呵。哎，有点扯远了，下面就来聊聊老王眼中的2016年电影之最。","text":"前言 初九，北京，阳光灿烂的日子。老天赏了个好脸色，仿佛在召唤村里的码农明天赶紧回来开工。隔壁老王平时比较喜欢赏片（别想歪2333），因此想趁着新的一年开工之前，再来回顾一下2016年那些经典的电影。 There are a thousand Hamlets in a thousand people’s eyes. —William Shakespeare 老莎说过，一千个人眼里就有一千个哈姆雷特。每个人都有自己喜欢的电影类型，这两年豆瓣上不乏“哈韩党”、“文艺装逼党”，高分的电影未必符合大众的审美，不一定好看。当然低分的国产电影，您也无需恼火，就像春节档上映的《西游伏妖篇》，特效还算不错，笑点还算凑合，虽然剧情烂了点，但是春节带着大朋友、小朋友们一起看看这种无厘头电影，乐呵乐呵，也是一种不错的体验，何况星爷是一位好的演员，但是从来也没有被承认过是一位好的导演和编剧。看到微博、豆瓣上面对这个片的好坏争得面红耳赤，真没这个必要。目前国内导演不是拍不出好的电影，而是意识形态所决定的，也不能全怨光腚总局，这个知乎好像有过讨论。况且你造每年美帝和棒子国也生产出很多烂片么？好片毕竟是少数。大家都这么忙，选自己喜欢的电影去消磨时间就OK啦，何必咸吃萝卜淡操心，人家吃你家一粒米啦？呵呵。哎，有点扯远了，下面就来聊聊老王眼中的2016年电影之最。 2016最好看的国产犯罪片 —《湄公河行动》 根据真实事件改编的缉毒大片，对于从小喜欢玩CS的我来说，整部电影燃到爆，肾上腺素爆表，爱国情怀爆棚。主旋律又如何，个人英雄主义又如何，美帝好莱坞不也是玩的也666么，例如《萨里机长》，看不惯国产电影中有这些元素的人真是被惯出来的。最后向缉毒警察致敬，感动！ 2016年最好看的荒诞喜剧 —《驴得水》 这是一部透露着悲剧色彩，处处充满讽刺的喜剧电影。影片中的每一位人物的性格都非常鲜明，也代表了那个年代中国的阶层背景。这部电影也可以解读为女权主义者的呐喊，对于性解放的抗争。豆瓣、知乎对于这部电影已经有非常多好的影评了，就不再班门弄斧了。这部电影的主题曲《我要你》真是唱的心痒痒呦。任素汐饰演的张一曼没的说，好演员不看颜值，赞！ 在知乎看到该片的导演编剧周申谈起这部影片，说从开始做到最后做成经历了7年的时间，一度困难重重，期间对于作品的追求让他们也拒绝了很多投资，一个靠谱的项目遇到了两个不靠谱的人，哈哈，最终周申和刘露坚守住了作品的底线，完成了一部艺术与商业兼修的好片，服！ 2016年最好看的国外战争片 —《比利·林恩的中场战事》 李安导演的在这一部电影中运用了新的拍摄技术，4K+120帧+3D，当时在电影院看这部片的时候应该不是120帧的，因此对于120帧到底牛逼在哪里，遗憾没能体会到。这张剧照非常有意思，这位大男孩回家了，他是一位英雄，有家人和佳人相伴，回到战场，是一名士兵，要忍受炮火和战友的牺牲。这位大男孩孤独的靠在墙边，这一天中各种画面在脑海中闪现，第一人称的视角也更具有带入感。他的故事，你懂了吗？愿世界和平！ 2016年最好看的动画片 —《疯狂动物城》 长大了，看动画片的次数就少了很多，16年最好看的动画片还是从众一下，给了这部迪士尼的片子。里面一些梗还记忆犹新，比如树懒的慢动作好想打他额，还有教父的经典片段COS，哈哈，像经典致敬，不错。各个方面都是一部不容错过的动画片。 2016年最好看的灾难片 —《釜山行》 2016这一年好看的韩国电影倒不少，例如《釜山行》《隧道》《小姐》等等，谈到灾难恐怖片，不得不提到这部《釜山行》，一部恐怖片里最可怕的是不是丧尸的恐怖，而是人性的丧失，例如上层官员对于真相的掩盖以及责任的逃避，那位大叔非常恶心的自私嘴脸等等，当然，影片中年轻小伙为了陪伴女友宁愿被咬死，大叔为了保护怀孕的妻子壮烈牺牲，石宇从最初的比较自私到最后牺牲自己拯救他人以及自己女儿的行为，都让人感动。最后士兵难道不能放空一枪么，晕…..一部僵尸片透露出这么多的内容，还是很值得国产恐怖片深思的，距离还有很远。 最后为啥老想到那句话，明知山有虎(釜)，偏向虎（釜）山行，额…… 2016年最好看的情色片 —《小姐》 作为一部同性片来看，先不说里面透露的深层含义，女权主义。连阅片无数的隔壁老王，看这部电影的时候，都无耻的硬了好几次，（捂脸逃……），朴赞郁真是个会讲故事的肮脏老头子呀，污的优雅，谁看谁知道，嘿嘿嘿 2016年最好看的励志片 —《垫底辣妹》 这片其实15年就已经在岛国上映，16年4月份才在大陆上映，讲述了一位漂亮的小姐姐不正干，在班里倒数垫底，中间被坪田老湿调教，发现自己还蛮有潜力的呢，带着她妈的亲情光环，闺蜜同学友情加持，绝地逆袭，考取了庆应大学文学系（还好不考数学啊…..），以大多数人的努力程度之低，根本轮不到去拼天赋，嗯哼，实属鸡汤励志电影佳作。其实还有一部《飞鹰艾迪》也是16年的励志好片，但是谁让爱学习的小姐姐这么漂酿清纯呢，就选你了~~ 2016年最好看的科幻片 —《奇异博士》 这一年的科幻大作不少，例如《奇异博士》、《X战警:天启》、《魔兽》、《美国队长3》、《死侍》等等。视觉特效没得说，大爱卷福，漫威动漫改编的电影，其中很多彩蛋关联也是看了影评才了解，纯商业大片，不知道再说些啥了，老司机开车不要玩手机啊2333。欢迎doctor加入复仇者联盟，不知道会不会出现在第三部系列作品当中呢？ 2016年最好看的历史传记片 —《斯诺登》 说起历史传记片，高分片非常多，但是这一年这种题材的片子看的少且我也比较俗，就选了一部最贴近生活的。棱镜事件确实非常震惊，其实美帝监听邮件、电话、聊天记录那一套，其他国家未必不存在。这部电影是把“爱国者”与公民隐私权的对立面放大了，事物均有两面性，还是值得深思的。影片中斯诺登的扮演者演技出众，IT屌丝气质与geek气质完美。最后也提醒大家在日常生活中多注意自己的隐私安全。 2016年最好看的爱情片 —《你的名字》 2016爱情片看的是最少的，感情不算顺利，期待2017年你的名字出现吧，哈哈，（逃 总结祝愿2017年涌现出更多的优秀国产片，单靠卖情怀，消费粉丝的ip电影少赚点钱吧（虽然不太可能，呵呵）。Whatever，明天开工大吉！","categories":[{"name":"电影","slug":"电影","permalink":"https://geminiguy.github.io/categories/电影/"}],"tags":[{"name":"电影","slug":"电影","permalink":"https://geminiguy.github.io/tags/电影/"},{"name":"2016","slug":"2016","permalink":"https://geminiguy.github.io/tags/2016/"}]},{"title":"Kafka Controller","slug":"Kafka-Controller","date":"2017-01-12T16:00:00.000Z","updated":"2017-01-17T09:33:27.000Z","comments":true,"path":"2017/01/13/Kafka-Controller/","link":"","permalink":"https://geminiguy.github.io/2017/01/13/Kafka-Controller/","excerpt":"前言目前网上针对Kafka Controller的分析文章不算少，但是大多比较散乱，不够系统，因此趁着这次部门分享Kafka的机会，将一些知识点进行了梳理总结，学习过程中参考了一些原理性的分析文章和0.10版本的源码。本文埋了一些细节坑，待有时间再回来补全吧。对于Kafka的研究水平有限，如果文章中出现错误，还望在评论区交流指正，谢谢。下面我们首先从基础概念开始讲起。","text":"前言目前网上针对Kafka Controller的分析文章不算少，但是大多比较散乱，不够系统，因此趁着这次部门分享Kafka的机会，将一些知识点进行了梳理总结，学习过程中参考了一些原理性的分析文章和0.10版本的源码。本文埋了一些细节坑，待有时间再回来补全吧。对于Kafka的研究水平有限，如果文章中出现错误，还望在评论区交流指正，谢谢。下面我们首先从基础概念开始讲起。 基础概念 什么是Controller： 从Kafka集群中选取一个broker作为controller，负责管理topic分区和副本的状态的变化，以及执行重分配分区之类的管理任务。 Replication总共经历了三个版本的迭代，其优点如下： 解决了Zk的split-brain问题，分区状态的一致性得到保障 更少的ZK监听器，减轻了Zk负载以及herd effect问题 Leader的变化针对Zk的读写可以批量操作，减少failover过程中的延迟 Controller将状态的改变直接通过RPC的方式通知相应broker，相比ZK队列方式更高效 名词解释 AR 当前已分配的副本列表 RAR 重分配过的副本列表 ORA 重分配之前的副本列表 分区Leader 给定分区负责客户端读写的结点 ISR “in-sync” replicas，能够与Leader保持同步的副本集合（Leader也在ISR中） 和controller相关的zookeeper路径说明 /controller：结点存放当前Controller信息 /brokers/ids/[brokerId]：存放集群broker信息，包括ip、端口、jmx信息 /brokers/topics：子目录为topic列表 /brokers/topics/[topic]：存放对应topic的各个分区AR /brokers/topics/[topic]/partitions/[partitionId]/state：结点存放当前topic各个分区的Leader、ISR、controller_epoch、leader_epoch等信息。 /admin临时结点，只有相关操作时才会存在 /admin/delete_topics： 要删除的一些topic /admin/reassign_partitions：指导重新分配AR的路径，通过命令修改AR时会写入到这个路径下 /admin/preferred_replica_election：分区需要重新选举第一个replica作为leader，即preferred replica。起到自动平衡Leader分配的作用，使用自带工具或者auto.leader.rebalance.enable=true均可 LeaderAndIsrRequest,UpdateMetadataRequest,StopReplicaRequestLeaderAndIsrRequest请求及响应123456789101112131415161718192021222324/*** controllerId：controller所在的brokerId* controllerEpoch：controller选举版本号* partitionStates：Map[(topic, partitionId), PartitionState]* liveLeaders：传入参数分区leader所在的broker集合*/public LeaderAndIsrRequest(int controllerId, int controllerEpoch, Map&lt;TopicPartition, PartitionState&gt; partitionStates,Set&lt;Node&gt; liveLeaders) &#123;...&#125;/*** controllerEpoch：controller选举版本号* leader：分区leader所在的broker Id* leaderEpoch：分区leader选举版本号* isr：当前ISR列表* zkVersion：分区在zookeeper上的状态信息，用作竞态更新* replicas：分区副本列表*/public PartitionState(int controllerEpoch, int leader, int leaderEpoch, List&lt;Integer&gt; isr, int zkVersion, Set&lt;Integer&gt; replicas) &#123; this.controllerEpoch = controllerEpoch; this.leader = leader; this.leaderEpoch = leaderEpoch; this.isr = isr; this.zkVersion = zkVersion; this.replicas = replicas;&#125; 请求响应流程：makeLeaders、makeFollowers具体逻辑留坑待填 UpdateMetadataRequest请求及响应12345678/*** 可以看到此构造函数和LeaderAndIsrRequest请求类构造函数参数基本一致* liveBrokers：存活的broker集合*/public UpdateMetadataRequest(int version, int controllerId, int controllerEpoch, Map&lt;TopicPartition, PartitionState&gt; partitionStates, Set&lt;Broker&gt; liveBrokers)请求响应：每个broker都维护了相同的缓存，更新MetadataCache实例中的chace字段和aliveBroker字段分别为topic对应的分区状态信息以及当前可用的broker列表 StopReplicaRequest请求及响应1234public StopReplicaRequest(int controllerId, int controllerEpoch, boolean deletePartitions, Set&lt;TopicPartition&gt; partitions)请求响应：1. ReplicaManager会移除replica所在的partition的Fetcher，即不再向该partition的leader拉取新的数据2. 再根据deletePartitions决定是否删除该replica对应的topic partition日志 Partition状态机 PartitionState四种分区状态如下： NonExistentPartition：该分区要么没有被创建过或曾经被创建过但后面删除了 NewPartition：分区创建之后已经分配了副本，但是还没有选举出Leader和ISR OnlinePartition：分区Leader一旦被选举出来，就处在该状态 OfflinePartition：如果leader选举出来后，leader broker宕机了，那么该分区就处于OfflinePartition状态 分区状态转换图针对OnlinePartition,OfflinePartition –&gt; OnlinePartition而言，有四种Leader选举器策略如下: OfflinePartitionLeaderSelector If at least one broker from the isr is alive, it picks a broker from the live isr as the new leader and the live isr as the new isr. Else, if unclean leader election for the topic is disabled, it throws a NoReplicaOnlineException. Else, it picks some alive broker from the assigned replica list as the new leader and the new isr. If no broker in the assigned replica list is alive, it throws a NoReplicaOnlineException Replicas to receive LeaderAndIsr request = live assigned replicas，Once the leader is successfully registered in zookeeper, it updates the allLeaders cache ReassignedPartitionLeaderSelector New leader = a live in-sync reassigned replicaNew isr = current isrReplicas to receive LeaderAndIsr request = reassigned replicas PreferredReplicaPartitionLeaderSelector New leader = preferred (first assigned) replica (if in isr and alive)New isr = current isrReplicas to receive LeaderAndIsr request = assigned replicas ControlledShutdownLeaderSelector New leader = replica in isr that’s not being shutdownNew isr = current isr - shutdown replicaReplicas to receive LeaderAndIsr request = live assigned replicas Replica状态机 ReplicaState副本状态如下： NewReplica：当创建了topic或者重分配分区时Controller会创建新的副本，就处在这个状态，此状态中的副本只能接收“成为follower”的状态变更请求，可由NonExistentReplica转换而来 OnlineReplica：一旦启动了一个副本以及该分区AR副本集合中的一部分，那么就将设置该副本状态为OnlineReplica。在此状态中的副本可以接收”成为leader”或”成为follower”的状态变更请求。可由NewRelica、OnlineReplica或OfflineReplica状态转换而来 OfflineReplica：如果一个副本挂掉(保存该副本的broker宕机)将被置于OfflineReplica状态，可由NewReplica或OnlineReplica状态转换而来 ReplicaDeletionStarted：开启副本删除操作时会将副本状态置于ReplicaDeletionStarted状态，可由OfflineReplica状态转换而来 ReplicaDeletionSuccessful：如果副本删除请求成功，返回的响应没有错误的话，该副本会被置于ReplicaDeletionSuccessful状态，可由ReplicaDeletionStarted状态转换而来 ReplicaDeletionIneligible：如果副本删除失败，将被置于ReplicaDeletionIneligible状态，可由ReplicaDeletionStarted状态转换而来 NonExistentReplica：如果副本被成功删除将被置于NonExistentReplica状态，可由ReplicaDeletionSuccessful状态转换而来 副本状态转换图 举例分析创建topic 命令行逻辑 12345bin/kafka-topics.sh --zookeeper XXX:12181 --create --topic fanstop_messagecore --partitions 2 --replication-factor 3a.确定分区副本的分配方案0 --&gt; [2,1,3]1 --&gt; [3,2,4]b.创建Zk结点，将分配方案写到 /brokers/topics/fanstop_messagecore 结点下 Controller后台逻辑 Controller启动时,分区状态机PartitionStateMachine.registerListeners()会注册一些监听器，当用命令行新增加了/brokers/topics/fanstop_messagecore结点后，就会触发监听器TopicChangeListener的handleChildChange方法，逻辑如下： 获取/brokers/topics路径下集合，与当前controller中保存的topic集合比较，找出新增topic集合，比如fanstop_messagecore（新增or删除） 更新controller的topic缓存列表 从/brokers/topics/fanstop_messagecore结点取出这个topic所有分区的分配方案，更新controller对应的缓存信息 调用KafkaController.onNewTopicCreation方法 onNewTopicCreation 123456def onNewTopicCreation(topics: Set[String], newPartitions: Set[TopicAndPartition]) &#123; info(\"New topic creation callback for %s\".format(newPartitions.mkString(\",\"))) // subscribe to partition changes topics.foreach(topic =&gt; partitionStateMachine.registerPartitionChangeListener(topic)) onNewPartitionCreation(newPartitions)&#125; 为每一个topic注册/brokers/topics/[topic]/下的分区变更监听器PartitionModificationsListener，本次仅注册但不会触发 调用onNewPartitionCreation方法创建分区 onNewPartitionCreation 1234567def onNewPartitionCreation(newPartitions: Set[TopicAndPartition]) &#123; info(\"New partition creation callback for %s\".format(newPartitions.mkString(\",\"))) partitionStateMachine.handleStateChanges(newPartitions, NewPartition) replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), NewReplica) partitionStateMachine.handleStateChanges(newPartitions, OnlinePartition, offlinePartitionSelector) replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), OnlineReplica)&#125; 创建新增分区对象，分区状态机将新创建分区转变为NewPartition状态 从Controller缓存中取出新增分区的副本分配方案，针对每一个replica进行NonExistentReplica–&gt; NewReplica状态转换 分区状态 NewPartition–&gt;OnlinePartition，调用initializeLeaderAndIsrForPartition(topicAndPartition)为新分区初始化leader和isr路径。主要策略就是让AR中第一个replica作为leader，所有可用的replica作为ISR，将leader、ISR、leaderepoch、controllerepoch、zkversion等信息写入Zk state节点，ControllerContext更新相应topic分区的leader和ISR缓存。之后就是发送LeaderAndIsrRequest给每个replica和UpdateMetadataRequest请求给每个可用的broker 设置副本状态机状态NewReplica—&gt;OnlineReplica，将当前的replica加入到controllerContext AR缓存中。完事…… Broker Failure下面来分析一下某台broker宕机的情况。 broker宕机后，zk会话超时，/brokers/ids对应结点被删除，触发BrokerChangeListener.handleChildChange，接着又调用controller.onBrokerFailure方法， 对Leader副本在deadBroker上的分区（同时要排除topic在删除的状态）触发OfflinePartition状态转换 这一步就是为处于OfflinePartition状态的分区触发OnlinePartition状态转换，ok，还记得上面提到的OfflinePartitionLeaderSelector选举器吧，这回就用它来进行Leader选举、ISR重分配，以及选出接收LeaderAndIsr请求的replica。更新一下Zk state结点的leader和ISR相关信息，更新controllerContext的leader缓存，给相应broker发送LeaderAndIsrRequest请求，顺带发送UpdateMetadataRequest请求，这些动作都是在electLeaderForPartition函数中完成 找出deadBroker上的所有副本，并且要过滤掉一些topics正在执行删除操作的replica，副本状态机执行OfflineRelica状态转换，过程不再赘述 check出正在执行topic删除期间的replica，将这些replica置为ReplicaDeletionIneligible，这些replica在broker down的时候是不能被删除的。 分区副本重新分配策略Kafka提供了分区重新分配的工具，在生产环境下，随着负载的增大，可能需要给Kafka集群扩容，但是对于已存在的topic，并不会自动将分区的副本迁移到新的Broker上，就可以用到这个工具。除此之外，我们还可以用这个工具来调整分区的AR数量，下面就来说一下Partition方案重新分配的情况，也涉及Controller非常重要的一个方法：onPartitionReassignment。当用命令行发起分区重分配操作时，它会在/admin/reassign_partitions路径下创建节点，进而触发PartitionsReassignedListener监听器，执行handleDataChange函数，过滤掉正在执行重分配的副本的分区，接着判断它们的topic是否正在进行删除，构造一个ReassignedPartitionsContext传递给controller.initiateReassignReplicasForTopicPartition为给定topic分区重新分配副本，这个函数的逻辑看了下源码，基本流程如下： 取出controllerContext针对这个分区的AR缓存，当前AR和RAR集合完全一样的的话，抛异常，不用重分配了 否则，判断一下RAR中是否存在不可用的副本，如果存在replica not alive，抛异常，此次重分配操作无法进行 如果RAR中均可用，注册Zk state结点的listen，监听ISR变化，mark一下该topic不能被删除。 最后一步调用最重要的函数onPartitionReassignment开始重新分配分区的副本 onPartitionReassignment这里我们还是以源码中的例子来说明整个流程:OAR = {1,2,3}RAR = (4,5,6) AR(Zk) leader/isr(Zk) transition {1,2,3} 1/{1,2,3} (initial state) {1,2,3,4,5,6} 1/{1,2,3} (step 2) {1,2,3,4,5,6} 1/{1,2,3,4,5,6} (step 4) {1,2,3,4,5,6} 4/{1,2,3,4,5,6} (step 7) {1,2,3,4,5,6} 4/{4,5,6} (step 8) {4,5,6} 4/{4,5,6} (step 10) 总结本文只举了三个经典的例子，后面再慢慢扩充用到Controller的实例分析吧。对于之前连Scala语法都没接触过的老王来说，整个调研学习过程真可谓折磨蛋疼额，技术无止境，共勉吧。However，还是希望本文能对读者有所帮助。 参考文献 官方wiki：Kafka Controller Internals 推荐Kafka相关博客 Kafka Controller源码分析","categories":[{"name":"技术","slug":"技术","permalink":"https://geminiguy.github.io/categories/技术/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://geminiguy.github.io/tags/Kafka/"},{"name":"Kafka Controller","slug":"Kafka-Controller","permalink":"https://geminiguy.github.io/tags/Kafka-Controller/"},{"name":"源码分析","slug":"源码分析","permalink":"https://geminiguy.github.io/tags/源码分析/"}]},{"title":"Hello World","slug":"index","date":"2016-12-31T16:00:00.000Z","updated":"2017-01-14T09:27:00.000Z","comments":true,"path":"2017/01/01/index/","link":"","permalink":"https://geminiguy.github.io/2017/01/01/index/","excerpt":"","text":"Hello world，隔壁老王新的一年博客开张个人比较懒，平时知识点也只是随手记录在印象笔记希望这一年能多写一些技术文章吧Whatever，新年快乐Ps：Hexo的环境配置真是好多坑啊，还是比较喜欢NexT这个主题","categories":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/categories/闲聊/"}],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/tags/闲聊/"}]}]}