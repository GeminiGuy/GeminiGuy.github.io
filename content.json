{"meta":{"title":"隔壁老王的Blog","subtitle":null,"description":"嘘，要发车了","author":"Gemini","url":"https://geminiguy.github.io"},"pages":[{"title":"categories","date":"2017-01-14T09:04:41.000Z","updated":"2017-01-14T09:12:51.000Z","comments":false,"path":"categories/index.html","permalink":"https://geminiguy.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-01-14T05:54:18.000Z","updated":"2017-01-14T06:02:54.000Z","comments":false,"path":"tags/index.html","permalink":"https://geminiguy.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Kafka Java消费框架","slug":"2017-05-30","date":"2017-05-29T16:00:00.000Z","updated":"2017-05-31T02:14:10.000Z","comments":true,"path":"2017/05/30/2017-05-30/","link":"","permalink":"https://geminiguy.github.io/2017/05/30/2017-05-30/","excerpt":"","text":"学着画了下Java消费框架的UML类图，如下所示","categories":[{"name":"技术","slug":"技术","permalink":"https://geminiguy.github.io/categories/技术/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://geminiguy.github.io/tags/Kafka/"},{"name":"Java","slug":"Java","permalink":"https://geminiguy.github.io/tags/Java/"},{"name":"消费框架","slug":"消费框架","permalink":"https://geminiguy.github.io/tags/消费框架/"}]},{"title":"kafka_datadispatch_framework","slug":"2017-05-27","date":"2017-05-24T16:00:00.000Z","updated":"2017-05-31T02:13:18.000Z","comments":true,"path":"2017/05/25/2017-05-27/","link":"","permalink":"https://geminiguy.github.io/2017/05/25/2017-05-27/","excerpt":"","text":"kafka_datadispatch_framework是我造的一个Kafka Python版本消费框架的轮子，通过继承相应类并重写相应方法进行二次开发，对于业务逻辑处理来说使用非常方便，框架思想借鉴了之前的RIN datadispatch。这个轮子应该属于基础服务框架，不涉及业务信息，回头申请一下再Github上面开源吧。 消费框架图 kafka_frame.py为整个消费框架的入口，其中parser_conf函数会解析指定的conf文件，加载需要启动的消费脚本及kafka基本配置信息。在load_app_mod中创建多个子进程，执行相应消费脚本中的run方法，run方法初始化fastlog模块，创建类对象，执行实例的rundeal方法，在父类rundeal方法的while循环中，KafkaConsumer去poll Kafka的数据，将拉取的record放入list中，交由重写的parser_data方法处理。对于停止消费框架，SIGTREM信号也是由kafka_frame父进程传递给各个子进程，等待各消费子进程安全退出后，父进程退出。","categories":[{"name":"技术","slug":"技术","permalink":"https://geminiguy.github.io/categories/技术/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://geminiguy.github.io/tags/Kafka/"},{"name":"消费框架","slug":"消费框架","permalink":"https://geminiguy.github.io/tags/消费框架/"},{"name":"Python","slug":"Python","permalink":"https://geminiguy.github.io/tags/Python/"}]},{"title":"The world beyond batch-Streaming","slug":"2017-05-24","date":"2017-05-23T16:00:00.000Z","updated":"2017-05-31T02:17:17.000Z","comments":true,"path":"2017/05/24/2017-05-24/","link":"","permalink":"https://geminiguy.github.io/2017/05/24/2017-05-24/","excerpt":"","text":"流式数据处理在当今变得愈发重要，有两篇Google大神Tyler Akidau的系列文章堪称经典，不得不看，mark一下，补充一下自己的理论基础知识。 《The world beyond batch: Streaming 101》 streaming 101原文链接 推荐个一直关注的博客，对于原文的翻译总结非常不错中文翻译 《The world beyond batch: Streaming 102》 Streaming 102","categories":[{"name":"技术","slug":"技术","permalink":"https://geminiguy.github.io/categories/技术/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://geminiguy.github.io/tags/Kafka/"},{"name":"streaming","slug":"streaming","permalink":"https://geminiguy.github.io/tags/streaming/"}]},{"title":"Oceanus浅聊","slug":"2017-05-23","date":"2017-05-22T16:00:00.000Z","updated":"2017-05-23T12:53:38.000Z","comments":true,"path":"2017/05/23/2017-05-23/","link":"","permalink":"https://geminiguy.github.io/2017/05/23/2017-05-23/","excerpt":"","text":"Oceanus，这个名字的灵感来源于古希腊神话中的一个泰坦，它的化身是环绕陆地的海洋，掌管着一切洋流，被称为让一切流动之神，让一切冻结之神，而广告数据总线Oceanus，就像数据流之神一样，掌管着一切广告数据的收集与分发，Oceanus也是是一个业务解决方案框架。当时起这个名字自我感觉还是比较有水平的，2333（逃 Oceanus框架图（持续更新…） 上面Oceanus框架图中既有自研也有很多现成开源的工具，其中有些技术例如Kafka Connector以及运维监控一整套流程，我也不是很了解，大数据方向众多，要学习的知识点也很多，加油共勉吧~~~","categories":[{"name":"技术","slug":"技术","permalink":"https://geminiguy.github.io/categories/技术/"}],"tags":[{"name":"Oceanus","slug":"Oceanus","permalink":"https://geminiguy.github.io/tags/Oceanus/"},{"name":"Kafka","slug":"Kafka","permalink":"https://geminiguy.github.io/tags/Kafka/"}]},{"title":"20170521周末杂","slug":"2017-05-21","date":"2017-05-20T16:00:00.000Z","updated":"2017-05-21T13:33:28.000Z","comments":true,"path":"2017/05/21/2017-05-21/","link":"","permalink":"https://geminiguy.github.io/2017/05/21/2017-05-21/","excerpt":"好久没打生活卡了，北京这天越来越热了，躁动，多说6.1号要关闭了啊，抓紧换个评论系统……","text":"好久没打生活卡了，北京这天越来越热了，躁动，多说6.1号要关闭了啊，抓紧换个评论系统…… 美食好久没做硬菜了，这周先来个红烧排骨+旱黄瓜炒西红柿 发现《孤独的美食家》绝对称得上一个人吃饭时的下饭神片~~，五郎，战歌走起…… 跑步打卡","categories":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/categories/闲聊/"}],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/tags/闲聊/"}]},{"title":"非粉定向建议实时数据挖掘","slug":"ctr-data-20170520","date":"2017-05-19T16:00:00.000Z","updated":"2017-05-20T01:56:31.000Z","comments":true,"path":"2017/05/20/ctr-data-20170520/","link":"","permalink":"https://geminiguy.github.io/2017/05/20/ctr-data-20170520/","excerpt":"序言好久没更新过技术博客了，上一篇的更新还是春天，转眼间帝都已然进入了夏天的节奏，这段时间恰好把Kafka Streams流式计算应用到了广告业务中，现记录下来，文章中的数据分析部分涉及公司商业信息，待老大同意再公开吧……","text":"序言好久没更新过技术博客了，上一篇的更新还是春天，转眼间帝都已然进入了夏天的节奏，这段时间恰好把Kafka Streams流式计算应用到了广告业务中，现记录下来，文章中的数据分析部分涉及公司商业信息，待老大同意再公开吧…… 需求背景目前非粉支持广告主按照二度关系、领域兴趣、指定账号粉丝三个部分进行广告投放，2017年粉条改版之后，在广告主购买高级定向包（兴趣包）时增加地域和性别维度的定向条件，实现更加多元化、精准化的流量投放，提高ECPM。为更好的指导广告主的条件定向，从而提高广告的CTR（点击率），帮助广告主提高ROI（投资回报率）。现决定以广告订单为单位实时计算各种组合条件的CTR，投放过程中或订单结束后在数据效果页进行展示，各个组合维度CTR top5，进而优化目前效果页固定的文字title~~ 技术架构技术解决方案主要用到的工具如下: Flume: 1.7 Farmer kafka_datadispatch_framework Kafka: 0.10.0.1 Kafka Streams: 0.10.0.1 Redis 主要分为以下几个模块 数据源拷贝模块 数据实时计算模块 数据缓存处理模块 数据源拷贝模块由于Flume1.7的Kafka Sink用到的还是Producer 0.9的协议，无法在record中添加timestamp字段值，而后续的流式计算Streams如果没有event time则会出现异常，而目前线上的互动日志是用Flume接到Kafka的，无法直接使用，同时笔者也不想在线上集群来测试这一套技术方案，因此将线上集群的互动日志和曝光日志用kafka_datadispatch_framework进行相应处理后接到测试集群。 数据实时计算模块其中数据实时计算模块是整个计算框架中的核心模块，数据清洗、过滤、连接、聚合等流式计算基本语义均在本模块有所体现，可见其逻辑重要性。吹完牛逼我们来看一下这一模块的技术框架图。 1. 互动、曝光解析过滤子模块 互动日志KStream利用map+filter解析过滤出有效非粉互动，对于曝光日志同理，输出topic及相应格式如下,(ps: 其实互动value里面很多信息并没有用到)： 12345678910111213141516171819topic: wb_extendfans_pvid_bhvkey: pvidvalue(json): &#123; \"code\": \"14000003\", \"clktime\": \"1495003701\", \"adid\": \"170503250165164982\", \"pvid\": \"01536016988612\"&#125;topic: wb_extendfans_pvid_expokey: pvidvalue(json): &#123; \"count\": \"10000\", //购买量 \"adid\": \"170503250165164982\", \"target\": \"2|301|20001,20002,20006\", // gender|area|fieldId \"pvid\": \"01536016988612\"&#125; 由于比较懒，不想多写代码，于是乎我用到了through将wb_extendfans_pvid_expo作为一个中间输出，后面接着处理曝光数据，利用flatMap API，将上面的KStream按照兴趣码拆分成多个KStream流，方便后期进行countby key。 123topic: wb_extendfans_expo_countsourcekey: adid@count@gender|area|field // 这里field为单个码, @ 为各个字段的分隔符value: \"1\" // value在这里已经不重要了 2. 互动join曝光子模块 接入上一个模块的两个输出源：wb_extendfans_pvid_bhv、wb_extendfans_pvid_expo做为进行join操作的两个KStream，并对field的组合继续用flatMap拆分多个数据流。最终输出topic及格式： 1234topic: wb_extendfans_bhv_join_expokey: adid@count@gender|area|field // 这里field为单个码, @ 为各个字段的分隔符value: &quot;1&quot; // 其实value在这里已经不重要了JOIN_WINDOWS = 2 * 60 * 60 * 1000L //时间窗口 3. 聚合计算ctr子模块 首先对购买量小于1W的数据流进行过滤，之后分别对互动组合和曝光组合的数据流进行count by key聚合，其中key如图所示，value即为实时递增的总数。针对两个KTable进行实时join关联，进行实时ctr计算。实时CTR=互动组合条件总数/曝光组合条件总数计算结果也是一个KTable，接着用.toStream.fileter.map变为一个实时变化的KStream，方便后期入缓存处理 123topic: extendfans_ctr_streamkey: adid@gender|area|fieldvalue: 此时的ctr@此时曝光量 数据缓存处理模块 这个模块相对于上个模块就简单太多了，利用kafka_datadispatch_framework消费extendfans_ctr_stream数据，且过滤掉此时曝光小于1000的噪声数据，实时写入redis进行存储，这里用到了redis有序集合，利用ZADD命令，写入同时可实时排序。 1234Rediskey: adidmember: 组合条件score: ctr 总框架图 数据结果分析与总结展望","categories":[{"name":"技术","slug":"技术","permalink":"https://geminiguy.github.io/categories/技术/"}],"tags":[{"name":"流式计算","slug":"流式计算","permalink":"https://geminiguy.github.io/tags/流式计算/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"https://geminiguy.github.io/tags/数据挖掘/"},{"name":"Kafka Streams","slug":"Kafka-Streams","permalink":"https://geminiguy.github.io/tags/Kafka-Streams/"}]},{"title":"Kafka Offset倒回和数据丢失","slug":"kafka-rewinds-data-lost","date":"2017-04-26T16:00:00.000Z","updated":"2017-04-27T03:46:31.000Z","comments":true,"path":"2017/04/27/kafka-rewinds-data-lost/","link":"","permalink":"https://geminiguy.github.io/2017/04/27/kafka-rewinds-data-lost/","excerpt":"序言 本文为之前的一篇文章的更新，写完一直没挂到博客上，现直接顶到最新日期吧。之前看过的客官请直接忽略。","text":"序言 本文为之前的一篇文章的更新，写完一直没挂到博客上，现直接顶到最新日期吧。之前看过的客官请直接忽略。 Kafka Offset Rewinds是什么？Kafka数据丢失又由哪些原因造成？如果读者对这些问题了如指掌，那么大神走好不送，这篇文章可以不用浪费时间了。本文首先对我们业务生产环境中遇到的offset rewinds问题做了一个详尽分析，接着引出unclean选举的问题，最后会对数据安全性的一些参数做相关说明。 Kafka Offset RewindsOffset Rewinds概念 Kafka的某个group的某个consumer进程（线程）由Coordinator分配了消费任务去fetch某个分区的数据后，会根据该group提交的offset去决定从分区的哪个偏移位置去开始消费。当然，如果这是一个新的group还没有提交过offset，或者之前提交的offset发生了越界错误，比如offset对应的位移的数据由于已过期日志已被删除，再比如，你想poll的那个位移处的数据还没有写入leader（wtf？这是有可能的，正是本文现象所讨论的，别急，往下看）。发生这些情况就会根据你的consumer实例初始化时设置的auto.offset.reset参数决定处理方式。设置为earliest，从leader能获取到的最小的位移偏移量开始拉取数据，设置为latest则初始化为最新的位移偏移量处开始poll数据进行消费。当发生“故障”而触发auto.offset.reset时，两者的区别只是重复消费数据量多少的区别。本文的offset rewinds概念主要是指offset位移偏移量倒回到最早的一条数据开始消费这种现象。 现象review及排查 先来看一下这个问题是如何被监控到的，我们的同学对于wb_userdata_ffk03新开了个group，将消费到的数据写入Influxdb并基于Grafana进行了监控，可以看到某天晚上19：00左右的时候消费的数据量比之前突增了五倍，同时Burrow也发出了lag堆积报警，查看Kafka-manager也可以看到几个堆积的分区在同一个broker上面。种种现象说明了我们的group发生了offset rewinds，从头开始消费。 以topic：wb_userdata_ffk03，partition：19，AR：[2,3]，ISR：[2,3], leader：2为例。去相应的broker上面进行日志排查，看看7点左右到底发生了什么。broker 2的controller.log显示如下： broker 1的controller.log 从上面两张截图可以看到broker 2在18:58:54时重新加入了，说明之前该结点被删过额，那第二张截图为何没有打印deleted brokers呢，只有一个原因，broker 2此时还是controller，囧啊。不过没有关系，下面这张截图broker 2 controller的日志明确验证了此时broker 2 session timeout，broker failure喽。 到目前为止，我们能够确信这个时间点，这个分区的leader 2确实failure了，但是为何会出现offset rewinds呢？悲剧继续上演…… 这张截图是broker 2的server.log，可以看到这时候replica 3从ISR中被踢出去了，此时ISR中就只有2了，接着leader 2又发生了宕机😶。 关于这个ISR状态的变化我再多说一点。什么情况下一个replica会被从ISR中踢出去呢？我们来大体看一下maybeShrinkIsr和getOutOfSyncReplicas两个函数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 def maybeShrinkIsr(replicaMaxLagTimeMs: Long) &#123; val leaderHWIncremented = inWriteLock(leaderIsrUpdateLock) &#123; leaderReplicaIfLocal() match &#123; case Some(leaderReplica) =&gt; val outOfSyncReplicas = getOutOfSyncReplicas(leaderReplica, replicaMaxLagTimeMs) if(outOfSyncReplicas.size &gt; 0) &#123; val newInSyncReplicas = inSyncReplicas -- outOfSyncReplicas assert(newInSyncReplicas.size &gt; 0) info(\"Shrinking ISR for partition [%s,%d] from %s to %s\".format(topic, partitionId,inSyncReplicas.map(_.brokerId).mkString(\",\"),newInSyncReplicas.map(_.brokerId).mkString(\",\"))) // update ISR in zk and in cache updateIsr(newInSyncReplicas) // we may need to increment high watermark since ISR could be down to 1 replicaManager.isrShrinkRate.mark() maybeIncrementLeaderHW(leaderReplica) &#125; else &#123; false &#125; case None =&gt; false // do nothing if no longer leader &#125; &#125; // some delayed operations may be unblocked after HW changed if (leaderHWIncremented) tryCompleteDelayedRequests()&#125;def getOutOfSyncReplicas(leaderReplica: Replica, maxLagMs: Long): Set[Replica] = &#123; /** * there are two cases that will be handled here - * 1. Stuck followers: If the leo of the replica hasn't been updated for maxLagMs ms, * the follower is stuck and should be removed from the ISR * 2. Slow followers: If the replica has not read up to the leo within the last maxLagMs ms, * then the follower is lagging and should be removed from the ISR * Both these cases are handled by checking the lastCaughtUpTimeMs which represents * the last time when the replica was fully caught up. If either of the above conditions * is violated, that replica is considered to be out of sync * **/ val leaderLogEndOffset = leaderReplica.logEndOffset val candidateReplicas = inSyncReplicas - leaderReplica val laggingReplicas = candidateReplicas.filter(r =&gt; (time.milliseconds - r.lastCaughtUpTimeMs) &gt; maxLagMs) if(laggingReplicas.size &gt; 0) debug(\"Lagging replicas for partition %s are %s\".format(TopicAndPartition(topic, partitionId), laggingReplicas.map(_.brokerId).mkString(\",\"))) laggingReplicas&#125; 在getOutOfSyncReplicas函数的注释中把replica剔除ISR的情况说的比较清楚。 1.这个replica fetch的进程stuck住了，该replica的leo超过maxLagMs没有更新了。 2. follower的拷贝速度远远跟不上leader的写入速度，已经持续落后了maxLagMs。 这两种情况都可以用lastCaughtUpTimeMs来计时，这个参数代表了这个replica上一次完全追上leader的时间戳。接着我们再来看一下ISR中只剩下2，而2又宕机了，肿么办，其实此刻该分区还是可以用的，因为默认开启了unclean.leader.election.enable这个功能，允许进行unclean选举，未能及时同步的replica 3被选举为leader，可以看到如下日志。 将上面所说的这些流程化如下： 1. [wb_userdata_ffk03,19]，ISR：[2,3]，leader：2 2. replica 3因跟不上leader 2的速度从ISR中被踢出来，ISR：[2] 3. leader 2和zk会话超时，/broker/ids节点被删，ISR中没有replica了，触发unclean选举，leader：3，ISR:[3]，HW变为3的leo 4. 分配到19分区的consumer进程（线程）继续从上一次消费完的offset的下一条开始poll数据，这个offset在leader 3的log中不存在（这些数据还没有从之前的leader 2 同步fetch过来），进而触发auto.offset.reset，这个因为设置的为earliest，因此从replica 3的log保存的最早的一条数据开始消费，造成offset rewinds现象 5. broker 2重新建立会话回来后，成为follower，log被截断至HW，HW到自己的leo之间的数据当然也就丢失了。 其他问题 其实造成offset rewinds的问题是并不局限于unclean leader election，剖析Linkedln遭遇的Kafka“危机故障”这篇文章中也介绍了LinkedIn之前遇到的一些Bug级别（目前已修复）的offset rewinds，以供参考。 小结 综上所述，由于unclean选举会触发auto.offset.reset且肯定会丢失数据，那你肯定会说这个功能关了不就ok了吗？自古美事两难全，我们在下一节来细说这个Unclean leader election。 Unclean leader election 是否允许unclean选举其实也是可用性和数据一致性的trade-off问题。官方文档针对unclean选举有这么一段，我结合自己的理解来翻译一下。 Unclean leader election: What if they all die?Note that Kafka’s guarantee with respect to data loss is predicated on at least one replica remaining in sync. If all the nodes replicating a partition die, this guarantee no longer holds.However a practical system needs to do something reasonable when all the replicas die. If you are unlucky enough to have this occur, it is important to consider what will happen. There are two behaviors that could be implemented: Wait for a replica in the ISR to come back to life and choose this replica as the leader (hopefully it still has all its data). Choose the first replica (not necessarily in the ISR) that comes back to life as the leader. This is a simple tradeoff between availability and consistency. If we wait for replicas in the ISR, then we will remain unavailable as long as those replicas are down. If such replicas were destroyed or their data was lost, then we are permanently down. If, on the other hand, a non-in-sync replica comes back to life and we allow it to become leader, then its log becomes the source of truth even though it is not guaranteed to have every committed message. By default Kafka chooses the second strategy and favor choosing a potentially inconsistent replica when all replicas in the ISR are dead. This behavior can be disabled using configuration property unclean.leader.election.enable, to support use cases where downtime is preferable to inconsistency. This dilemma is not specific to Kafka. It exists in any quorum-based scheme. For example in a majority voting scheme, if a majority of servers suffer a permanent failure, then you must either choose to lose 100% of your data or violate consistency by taking what remains on an existing server as your new source of truth. 需要注意的是，kafka对于数据丢失的保障是基于ISR中至少一个副本在保持同步。如果该分区上所有的副本结点都挂了，那这保证就不再成立了。然后实际系统需要对所有replica die的情况进行处理。如果你人品不好遇到了这种情况，需要考虑以下两种处理方式，就变得至关重要了： 等着ISR中的一个副本活过来，并选举它为leader 选择第一个活过来的副本（不一定在ISR中）作为leader 其实这就是针对可用性和一致性的简单权衡了。如果选择等待ISR中的一个副本，那么只要ISR中的replica一直down，ok，那么这个分区就不可用，如果这些replica损坏或者数据丢失（管它什么原因），那就是永久的不可用了。另一个方面，如果我们选择了一个不是ISR中的replica作为leader，那它的log将成为数据源，即使它的log中并不能够保证拥有每条已经被commited的消息。目前我们用的版本中默认是选择了第二种处理方式，如果ISR中的所有replica挂了就选择了一个潜在数据不一致的replica作为leader。如果我们对于数据一致性的要求比宕机可用性的要求更高，就可以通过unclean.leader.election.enable=false禁用掉，这个可以细化到某个topic级别。这里我多说一句什么是committed消息，如果一条消息被ISR中所有的replica记录到log中，那么这条消息就被认为是committed的，对于consumer端而言，只有被committed的消息才能被看到，而High Watermark就是最新的的一条committed message的位移。 这种窘境也不只Kafka存在，任何基于quorum的方案中都会存在。例如在多数投票的方案中，如果多数的服务器将可能永久不可用，你是选择100%丢失数据呢？还是违反一致性，用幸存的服务器上还有的数据作为新的数据源？ 数据安全性保证的参数 下面来列举一下涉及数据安全性的相关参数，这里因producer的retry机制而max.in.flight.requests.per.connection&gt;1造成的消息乱序问题不在讨论之列。 1. replication.factor=3，副本因子设为3，有三份备份。 2. ACK=all(-1)，min.insync.replicas=2，两个参数配合使用，意味着producer至少要同步写进两个replica的log中，这条消息才被返回正常相应。这样设置后producer的吞吐量必然会下降，且如果某个分区有两个replica不可用的话，那么producer端就会触发NotEnoughReplicas或NotEnoughReplicasAfterAppend的异常。 3. unclean.leader.election.enable=false，这个上面已经详细分析过，数据一致性和可用性的权衡。 总结 本文针对unclean leader选举造成的offset rewinds情况进行了实际的分析，进而对数据安全性相关的参数进行了说明。However，针对不同的业务场景进行数据可用性与数据一致性的权衡、吞吐量与数据完整性的权衡，是非常重要的。当然最重要的还是保证Kafka集群的的稳定和健康。","categories":[{"name":"技术","slug":"技术","permalink":"https://geminiguy.github.io/categories/技术/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://geminiguy.github.io/tags/Kafka/"},{"name":"数据一致性","slug":"数据一致性","permalink":"https://geminiguy.github.io/tags/数据一致性/"},{"name":"高可用性","slug":"高可用性","permalink":"https://geminiguy.github.io/tags/高可用性/"}]},{"title":"20170326周末杂","slug":"20170326","date":"2017-03-25T16:00:00.000Z","updated":"2017-03-27T02:25:11.000Z","comments":true,"path":"2017/03/26/20170326/","link":"","permalink":"https://geminiguy.github.io/2017/03/26/20170326/","excerpt":"哔，照常打卡……","text":"哔，照常打卡…… 跑步打卡 老王私房菜之油焖大虾 忽略摆盘,西红柿放了俩，酱汁比较多，还是狠好吃的","categories":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/categories/闲聊/"}],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/tags/闲聊/"}]},{"title":"20170319周末杂","slug":"20170319","date":"2017-03-18T16:00:00.000Z","updated":"2017-03-20T02:16:50.000Z","comments":true,"path":"2017/03/19/20170319/","link":"","permalink":"https://geminiguy.github.io/2017/03/19/20170319/","excerpt":"调整生活习惯及作息，防过敏……","text":"调整生活习惯及作息，防过敏…… 跑步打卡 做饭打卡 关于过敏这周有三天作息不规律，晚上基本都一点睡觉，周五脸部就过敏了，晕死，还以为食物中毒或者化妆品过敏了呢，周日跑了步，然后上半身又起了胆碱性荨麻疹，醉了……解决方法： 第三代的抗组胺药作为首选。如盐酸左西替利嗪、地氯雷他定、盐酸司他斯汀等。 红豆薏米枸杞粥 规律作息，晚上11：30之前睡觉（重要） 饮食调节 关于技术文章这周一直在忙项目和基础沉淀，一直没有产出，憋个大招吧！！！","categories":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/categories/闲聊/"}],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/tags/闲聊/"}]},{"title":"20170312周末杂","slug":"20170312","date":"2017-03-11T16:00:00.000Z","updated":"2017-03-12T15:22:49.000Z","comments":true,"path":"2017/03/12/20170312/","link":"","permalink":"https://geminiguy.github.io/2017/03/12/20170312/","excerpt":"毫无营养的周末流水账","text":"毫无营养的周末流水账 老王私房菜之西红柿炖牛腩这次牛腩买的老筋多，口感不是很好，其次冰糖放多了，感觉四颗足矣，反而干辣椒可以多放两个，花椒也可以多放一点，味道应该会更好。 跑步打卡 本周三、周六各一次，继续坚持，再过段时间，是该换双新的跑鞋了。 手游之王者荣耀 都说这游戏小学生多，就上去看了下，然后每当队友不给力时，都觉得那个英雄是个小学生。玩了大半天，真是浪费生命，好想狗带。","categories":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/categories/闲聊/"}],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/tags/闲聊/"}]},{"title":"震惊，Kafka出大事儿了","slug":"kafka-talk","date":"2017-03-04T16:00:00.000Z","updated":"2017-03-07T01:55:21.000Z","comments":true,"path":"2017/03/05/kafka-talk/","link":"","permalink":"https://geminiguy.github.io/2017/03/05/kafka-talk/","excerpt":"序使用Kafka也有几个月的时间，然而期间出现了一件怪事儿，背后隐藏着怎样的惊天秘密呢？看完以后倒吸一口凉气，令人不解，男默女泪~~ （ps：uc体实在编不下去了，逃","text":"序使用Kafka也有几个月的时间，然而期间出现了一件怪事儿，背后隐藏着怎样的惊天秘密呢？看完以后倒吸一口凉气，令人不解，男默女泪~~ （ps：uc体实在编不下去了，逃 遇到的问题及分析Kafka使用过程中出现过一个比较严重的问题，每天都会有若干个的broker不定时间的触发SessionExpirationListener，也就是broker与zk的session出现超时，默认为6s，少则十几次，多则二十多次。broker与zookeeper的会话超时有多方面的原因，例如broker gc、主机cpu、memeory、网络资源不足、zk端hang on等等。下面一一进行排查。 zookeeper.session.timeout.ms默认为6000(6s)，出现session timeout又重新和zk建立了session时，SessionExpireListener的handleNewSession被触发，相当于重新在/broker/ids/下注册broker结点信息，接着触发BrokerChangeListener的handleChildChange方法。从zk的/broker/ids结点因超时被删除到重新建立这个过程，90%的情况都在1个ticktime（2s）搞定，也就是说超时后2s又回来了。ok，接着我就去broker的server.properties中把zookeeper.session.timeout.ms=12000。 然并卵，情况并没有缓解多少。绝大部分情况还是2s后会话又重新建立了，囧，玩我呢。之后我就去查究竟什么原因导致的这个会话超时。针对这个问题，很多人会说查gc啊，好，查gc，把出问题时间段的gc日志拉出来，对所有的gc时间排序（管它的是young gc还是full gc，管它是stw以及可以和用户线程并发执行的），排除这个原因，囧。 broker端cpu（12核机器占满6核，这个还待研究），memory和网络资源都没问题。zk端这些资源更充足了，也不是这个原因。而且几台broker的Byte in和Byte out都不算高。 zk hang on，排除。 怎么破，只能试着再提升下超时时间。 zookeeper.connection.timeout.ms=12000zookeeper.session.timeout.ms=20000 改完这个配置，最近五天内只出现了一次zk expire的情况，真是醉了。这只能算是一个治标不治本的方法把，哎 Final这个问题暂时作为一个未解之谜吧，或许有一天就突然发现了呢。这周六做的农家小炒肉真是失败，关键是小区门口超市没有猪后腿肉了，以后想做肉菜还得去趟大超市采购。周末跑步打卡贴一下，不然如何对得起这个闲聊tag，闪人~~","categories":[{"name":"技术","slug":"技术","permalink":"https://geminiguy.github.io/categories/技术/"}],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/tags/闲聊/"},{"name":"Kafka","slug":"Kafka","permalink":"https://geminiguy.github.io/tags/Kafka/"}]},{"title":"17年，狼叔再见","slug":"jinganglang3-Logan","date":"2017-03-03T16:00:00.000Z","updated":"2017-03-06T09:16:33.000Z","comments":true,"path":"2017/03/04/jinganglang3-Logan/","link":"","permalink":"https://geminiguy.github.io/2017/03/04/jinganglang3-Logan/","excerpt":"英雄迟暮，X时代的终结","text":"英雄迟暮，X时代的终结 周五下了班，和组里的小伙伴骑车从软件园20分钟赶到上地那边的影院，看了这部《金刚狼3：殊死一战》，说到“殊死”一词，其实这部影片中的战斗戏份相比以往少了许多，一是国内引进这部R级大片的时候已删了14分钟的片段（回头一定回刷完整版），二来英雄老矣。这部影片中的X战警成员只剩下金刚狼和X教授，X教授患上了阿尔茨海默病，发作时无法控制自己的能力，在墨西哥边境隐居，饱受病痛折磨，而金刚狼身边的战友以及女友们都已不在（真是克女友命），整日抑郁消沉，饮酒度日，超能力也下降了很多。 有一天，一位陌生女子让罗根送一个叫劳拉的女孩去加拿大边境，Logan从一开始的拒绝到逐步了解背后的真相，一路带着自己的“女儿”劳拉，躲避黑暗势力的追杀，期间X教授也挂掉了，Logan在和变异“金刚狼”玩命打斗中也光荣牺牲。一群小屁孩得以脱险（那位小黑胖子莫名喜感啊），整部电影多了些温情，颇有点《这个杀手不太冷》的意思。片中劳拉其实是由罗根的血清被克隆出来的小金刚狼（在《天启》最后彩蛋中有提到血清一事）。 虽然X战警和金刚狼的几部电影都有看过，但是对于休·杰克曼这位演员也是各种科普后才算了解。17年来为了这一个角色的坚持，从未间断过身材的保持，X战警中的演员可能就金刚狼这个角色从未换过演员吧，值得敬佩的好演员，也算是一个时代的经典。以下几张图片转自豆瓣的一篇影评，都是回忆啊，推荐一下。生活和时间才是永远的对手，超级英雄也无力对抗 整个观影过程中，时不时地都会去看下手机上的时间，总想让时间过得慢一些，电影不要这么快结束，然而待字幕结束，并没有等来期待的彩蛋，幕黑灯亮，人们纷纷散场，X英雄们，再见，Logan，再见了……","categories":[{"name":"电影","slug":"电影","permalink":"https://geminiguy.github.io/categories/电影/"}],"tags":[{"name":"电影","slug":"电影","permalink":"https://geminiguy.github.io/tags/电影/"},{"name":"金刚狼","slug":"金刚狼","permalink":"https://geminiguy.github.io/tags/金刚狼/"}]},{"title":"周末瞎扯淡","slug":"周末瞎扯淡","date":"2017-02-25T16:00:00.000Z","updated":"2017-02-28T12:34:57.000Z","comments":true,"path":"2017/02/26/周末瞎扯淡/","link":"","permalink":"https://geminiguy.github.io/2017/02/26/周末瞎扯淡/","excerpt":"序言周末瞎扯淡，记个流水账。","text":"序言周末瞎扯淡，记个流水账。 老王私房菜每周继续坚持做一道新菜，周六吃完烤肉，周日吃点素吧。西葫芦炒西红柿，味道还是很不错的。Ps：md，想试着做炒面，上周那种湿面差点又把我的炒锅给毁了，日了🐩了，果断弃之~~ 意外发现周六早晨躺床上被微博的一个游戏视频广告吸引了，《梦幻西游无双版》，下下来玩了一下，没想到历经了13年的回合制游戏还是出了即时战略版本啊，容我怀个旧~~ 还记得当年的海底沉船么，最后的boss那里是否还能遇到多年后变成大侠的自己呢？已然记不太清楚了。。。。。。 健身打卡 周日跑步打个卡，逐渐加量吧，下一周争取能跑10的速度，再加个1KM，恩，每周坚持至少两次跑步。","categories":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/categories/闲聊/"}],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/tags/闲聊/"}]},{"title":"Kafka Controller填坑","slug":"kafka-controller-makeLeader&Follower","date":"2017-02-18T16:00:00.000Z","updated":"2017-02-19T08:54:06.000Z","comments":true,"path":"2017/02/19/kafka-controller-makeLeader&Follower/","link":"","permalink":"https://geminiguy.github.io/2017/02/19/kafka-controller-makeLeader&Follower/","excerpt":"序言 阳光明美日，正是填坑时 之前有一篇Kafka Controller的文章中，对于RelicaManager的makeLeaders、makeFollowers方法具体实现逻辑留了一个坑，时隔好久，回来把这个坑补上，其中参考了0.10版本的scala源码以及两篇博客，最后参考文献中会有注明。","text":"序言 阳光明美日，正是填坑时 之前有一篇Kafka Controller的文章中，对于RelicaManager的makeLeaders、makeFollowers方法具体实现逻辑留了一个坑，时隔好久，回来把这个坑补上，其中参考了0.10版本的scala源码以及两篇博客，最后参考文献中会有注明。 ReplicaManager.makeLeaders 首先对于接收到makeLeaders请求的broker来说，对于每一个本地的replica将成为leader的partition，移除该partition的Fetcher，因为如果本地replica不再是follower，就不需要从leader拉取消息了。 对每个partition调用partition.makeLeader方法： 更新allReplica列表，对于新增的replica要创建log、 初始化highWater等等。对于当前分配的replica不在allReplicas中，则需要从assignedReplicas中删除。 更新Partition对象的ISR，controllerEpoch，leaderEpoch，zkVersion等信息。 如果本地replica之前不是leader，成为了leader，需要更新leader replica的highWater。 把所有remote replica的leo重置了成UnknownOffsetMetadata（-1），在maybeIncrementLeaderHW中会取所有replica中最小的leo，如果除leader外有其他replica，因为刚被重置过，最小leo一定是-1，-1一定小于当前的hw，所以hw其实不会被increment。只有当isr中只有leader时，那hw会被increment到leader.leo。 ReplicaManager.makeFollowers 针对本地每一个replica将成为follower的分区，调用partition.makeFollower方法。 partition.makeFollower中，更新partition的controllerEpoch、ISR（初始化为空）、leaderEpoch、zkVersion等信息。 更新allReplica列表，对于新增的replica要创建log、 初始化highWater等等。对于当前分配的replica不在allReplicas中，则需要从assignedReplicas中删除。 如果partition的leader发生变化，返回true，partition加入partitionsToMakeFollower set中，否则，返回false。 针对partitionsToMakeFollower，移除旧的Fetcher。 如果leader发生了变化，之前同步的数据和新的leader可能不一致，也有可能之前作为leader的leo大于现在leader的leo，因此需要把log截断至highWater。 如果当前broker没有在shuttingDown的话，添加新的leader的Fetcher __consumer_offsets的特殊情况 partition中topic为__consumer_offsets的特殊情况处理，对于新成为的leader，调用coordinator.handleGroupImmigration方法，进而调用groupManager.loadGroupsForPartition方法，将从log中把属于当前分区的Offset项恢复到OffsetCache中。对于新成为的followers，coordinator.handleGroupEmigration方法中进而调用groupManager.removeGroupsForPartition方法，清除之前的属于该partition的消费者组提交的offset缓存。 参考文献 Kafka源码阅读-KafkaController(2) Apache Kafka源码分析 - KafkaApis","categories":[{"name":"技术","slug":"技术","permalink":"https://geminiguy.github.io/categories/技术/"}],"tags":[{"name":"Kafka Controller","slug":"Kafka-Controller","permalink":"https://geminiguy.github.io/tags/Kafka-Controller/"}]},{"title":"周六杂记—壹贰叁","slug":"Note-20170218","date":"2017-02-17T16:00:00.000Z","updated":"2017-02-18T16:14:51.000Z","comments":true,"path":"2017/02/18/Note-20170218/","link":"","permalink":"https://geminiguy.github.io/2017/02/18/Note-20170218/","excerpt":"杂记壹 回顾这一周，好像都在应付各种小项目开发，粉条2017年改版大项目启动，设计评审会加各种对接口格式又是两天的时间。用来学习基础jvm知识的时间大大被压榨，买的《人类简史》和《未来简史》也沉睡了好几天。However，最重要的是，我的锅也沉睡许久，是时候唤醒它了~~ 之前设想的是每周都学做一道新菜，不仅是因为我司食堂太难吃，也是让自己的码农生活不要过得太屌丝吧，多一些正能量，或许就成了程序猿界的“厨神”了呢？😁周六早上反而睡不久了，于是乎起床买菜，在超市里看到了新鲜的湿面，这是个悲剧的前戏……","text":"杂记壹 回顾这一周，好像都在应付各种小项目开发，粉条2017年改版大项目启动，设计评审会加各种对接口格式又是两天的时间。用来学习基础jvm知识的时间大大被压榨，买的《人类简史》和《未来简史》也沉睡了好几天。However，最重要的是，我的锅也沉睡许久，是时候唤醒它了~~ 之前设想的是每周都学做一道新菜，不仅是因为我司食堂太难吃，也是让自己的码农生活不要过得太屌丝吧，多一些正能量，或许就成了程序猿界的“厨神”了呢？😁周六早上反而睡不久了，于是乎起床买菜，在超市里看到了新鲜的湿面，这是个悲剧的前戏…… 人生不只有苟且的工作，还有眼前的凉拌花生米和辣子鸡 杂记贰 下午看了会《未来简史》，睡了一觉醒来六点多了。晚饭吃点啥呢？凉拌花生米没有吃完，干脆下早上买的湿面吧，悲剧开始了…… 内心OS：好想拿刀砍了这湿面 杂记叁 晚上一个也住在附近的师弟要过来找我谈心，我的煮面小奶锅毁了，我也要出去散散心，😶，出去溜了一圈，果然有收获，见图。 一辆废弃的加长林肯，孤独的守候在五环外的马路边，“辽”字车牌隐约可见。这位东北大哥曾经的辉煌，你读懂了吗？ 杂记终最后以《乘风破浪》里的一句经典台词作为这篇毫无逻辑的杂记文章的结尾吧。 我的梦想，歌舞厅里只唱歌，桑拿馆里就洗澡！ 还有一首非常好听的歌曲推荐，500 Miles，晚安，好梦~~","categories":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/categories/闲聊/"}],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/tags/闲聊/"},{"name":"美食","slug":"美食","permalink":"https://geminiguy.github.io/tags/美食/"}]},{"title":"Ckestrel框架浅析","slug":"ckestrel框架浅析","date":"2017-02-11T16:00:00.000Z","updated":"2017-02-12T07:40:58.000Z","comments":true,"path":"2017/02/12/ckestrel框架浅析/","link":"","permalink":"https://geminiguy.github.io/2017/02/12/ckestrel框架浅析/","excerpt":"概述 Kestrel是一个利用Scala语言编写的轻量级消息队列，由Twitter团队开源，其支持三种协议：memcache、thrift、text。Kestrel具有高性能、代码轻量级、持久存储（记录读写日志到journal）、可靠性（支持可靠获取）等优点。而本文所要说的Ckestrel是Kestrel的C++版本，由团队的老前辈改版而成，采用的协议是memcached文本协议。由于吞吐量、稳定性、代码维护性等等原因满足不了业务需求，因此逐步会被Kafka取而代之。这篇文章是我15年刚入职那会调研学习这个框架的源码所写的wiki，现照搬到我的博客上面。本文将对Ckestrel的线程模型及状态机、持久化日志和可靠性读取机制等方面做相关分析。","text":"概述 Kestrel是一个利用Scala语言编写的轻量级消息队列，由Twitter团队开源，其支持三种协议：memcache、thrift、text。Kestrel具有高性能、代码轻量级、持久存储（记录读写日志到journal）、可靠性（支持可靠获取）等优点。而本文所要说的Ckestrel是Kestrel的C++版本，由团队的老前辈改版而成，采用的协议是memcached文本协议。由于吞吐量、稳定性、代码维护性等等原因满足不了业务需求，因此逐步会被Kafka取而代之。这篇文章是我15年刚入职那会调研学习这个框架的源码所写的wiki，现照搬到我的博客上面。本文将对Ckestrel的线程模型及状态机、持久化日志和可靠性读取机制等方面做相关分析。 CKestrel线程模型及状态机线程模型 Ckestrel采用了memcached的线程模型来处理网络连接，而memcached使用libevent实现异步服务器，采用主线程和worker线程，主线程负责监听网络连接，并且accept连接。当监听到连接时，accept连接成功后，把相应的client fd丢给其中一个worker线程。worker线程接收主线程丢过来的client fd，加入到自己的epoll监听队列，负责处理该连接的读写事件。memcached的线程模型图如下所示： 主线程通过evnet_init()为自己分配一个event_base，用于监听连接，即listen fd。 主线程创建n个worker线程，同时每个worker线程也分配了独立的event_base。每个worker线程通过管道方式与主线程进行通信，调用pipe函数，产生两个fd，一个是管道写入fd（notify_send_fd），一个是管道读取fd（notify_receive_fd）。worker线程把管道读取fd（notify_receive_fd）加到自己的event_base，监听管道读取fd的可读事件，即当主线程往某个线程的管道写入fd写数据时，触发事件。 主线程监听到有一个连接到达时，accept连接，产生一个client fd，然后选择一个worker线程，把这个client fd包装成一个CQ_ITEM对象（其中不仅有client fd参数，还包括init_state、event_flags、read_buffer_size等参数）然后压到worker线程的CQ_ITEM队列里面去（每个worker线程有一个CQ_ITEM队列），同时主线程往选中的worker线程的管道写入fd中写入一个字符“c”（Ckestrel中写入””，用来触发worker线程）。 某个worker线程监听到自己的管道读取fd可读，触发事件处理函数thread_libevent_process，从CQ_ITEM队列中取出CQ_ITEM对象，调用conn_new函数把此client fd加入到自己的event_base中，从此负责该连接的读写工作。 状态机 主线程和worker线程都调用conn_new函数进行事件监听，有事件发生时调用event_handler函数，最终执行driver_machine函数。状态机drive_machine函数是worker线程处理网络请求业务的逻辑核心。while循环中包含switch case，根据连接对象conn的当前连接状态state进入不同的case，每个case可能会改变conn对象的连接状态，进而被分发到合适的case上进行处理，最终由stop=true的case分支退出while循环。详细的解析请参考Memcached源码分析之请求处理。 Ckestrel持久化日志 Ckestrel日志文件是唯一在硬盘存储队列内容的方式，日志文件中顺序记录每个针对相应队列的添加和删除操作。每种操作有对应的flag来记录日志类型，flag总共有以下几种：CMD_ADD、CMD_ADDX、CMD_ADD_XID、CMD_REMOVE、CMD_REMOVE_TENTATIVE、CMD_SAVE_XID、CMD_UNREMOVE、CMD_CONFIRM_REMOVE。其中CMD_ADDX和CMD_ADDXID操作会利用自定义的pack压缩方式将某条队列消息的length、xid、addTime、expiry、data等信息写入日志文件中。Ckestrel服务器启动时，对每个队列的日志文件执行replayJournal操作，重新建立内存中的队列以便客户端访问。这种方式保证了即使服务器崩溃，也能根据每个队列的日志文件重建内存中的队列消息。 Ckestrel框架在对journal处理上与目前scala 2.4.1版本上有些区别。Journal.cc中实现了roll机制对日志文件进行压缩。在PersistentQueue.cc中的add方法中： 1234567891011if (keepJournal_ &amp;&amp; !journal_-&gt;inReadBehind()) &#123; if (journal_-&gt;size() &gt; maxJournalSize_ * maxJournalOverflow_ &amp;&amp; queueSize_ &lt; maxJournalSize_) &#123; slog_write(LL_NOTICE, \"Rolling journal file for '%s' (qsize=%d)\", name_.c_str(), queueSize_); deque&lt;QItem *&gt; q = openTransactionQItems(); journal_-&gt;roll(xidCounter_, q, queue_); &#125; if (queueSize_ &gt;= maxMemorySize_) &#123; slog_write(LL_NOTICE, \"Dropping to read-behind for queue '%s' (%lu bytes)\", name_.c_str(), queueSize_); journal_-&gt;startReadBehind(); &#125; &#125; 利用kestrel.conf配置文件设置 maxJournalSize = 16M，maxJournalOverflow = 10，maxMemorySize = 128M。初始向队列写入数据时，journal不会进入ReadBehind模式。当日志文件大小大于maxJournalSize * maxJournalOverflow并且队列大小小于maxJournalSize时，journal进行roll操作，重新建立日志文件，将内存中的队列消息add进journal_日志中，其中利用pack编码方式，opcode=CMD_ADDX。同样将openTransactionQItems中未完成的事务记录在对应日志当中。 当队列大小大于等于maxMemorySize_时，启动ReadBehind模式，后面写入队列的消息将会存储在日志文件中，每当从内存中remove掉消息的时都会尝试从日志文件中读取相关队列消息再pushback到内存队列中，这种状态一直持续到reader和writer_指针重合，即在ReadBehind模式下add进日志文件的消息均被处理完毕，退出ReadBehind模式。 另外在PersistentQueue.cc中remove方法中，当if (queueLength == 0 &amp;&amp; journal -&gt;size() &gt;= maxJournalSize_)时，也会对日志文件进行roll操作。 可靠性读取 默认的GET并没有加入可靠性读取选项，从队列中获取消息后，server端就将该消息从队列中移除，如果客户端在处理这个消息的时候异常崩溃或者在接收消息时连接断开，则该条队列数据就会永久丢失，而之前出现的RIN数据丢失问题则出现在这里。这种默认的方式是不安全的，因此Kestrel提供了可靠性读取机制，在GET命令中加入/open和/close选项。官方文档对/open和/close的描述如下： /openTentatively remove an item from the queue. The item is returned as usual but is also set aside in case the client disappears before sending a “close” request. /closeClose any existing open read. 当在消费机客户端GET命令中使用/open时，kestrel服务器将这个消息从队列暂时移除并正常发送给消费机客户端，同时在openTransactions这个map容器中备份该队列数据，如果这时候客户端崩溃或者断开连接，从openTransactions中根据xid键取出该队列数据，重新放入内存队列头部，因此当客户端重新连接后就可以获取到该队列消息。每个连接的client只能有一个正在执行的可靠获取，再次发送带有/open选项的GET命令server返回空（同一个连接直接发送GET命令也会返回空）。当消费机客户端收到该队列数据时，再次发送带/close选项的GET命令，server将会confirmRemove该队列数据，从openTransactions_容器中删除这条队列数据，并在日志文件中记录CMD_CONFIRM_REMOVE。 具体分析发送完带/open选项的GET命令后，消费机与队列机服务器断开连接，则进入Ckestrel.cc中的conn_close函数，执行qc-&gt;unremove操作。 12345678static void conn_close(conn *c)&#123; if (c-&gt;xid) &#123; if (qc-&gt;unremove(std::string(c-&gt;xkey, c-&gt;xnkey), c-&gt;xid) == false) &#123; slog_write(LL_WARNING, \"Unremove non-existent transaction\"); &#125; c-&gt;xid = 0; &#125;&#125; 最终进入PersistentQueue.cc的doUnremove函数，在openTransactions_容器中根据上一条队列消息的xid找到该item，再pushfront到内存队列头部，在openTransactions容器中删除该队列消息。客户端重新连接到服务器后，就可以从服务器内存队列中取到该条队列消息，这就是kestrel的可靠读取机制的实现。 123456789101112bool PersistentQueue::doUnremove(int xid) &#123; map&lt;int, QItem*&gt;::iterator it = openTransactions_.find(xid); if (it != openTransactions_.end()) &#123; queueLength_ += 1; queueSize_ += it-&gt;second-&gt;getLength(); queue_.push_front(it-&gt;second); memoryBytes_ += it-&gt;second-&gt;getLength(); openTransactions_.erase(it); return true; &#125; return false;&#125; 总结 本文从Kestrel的线程模型、状态机、持久化日志、可靠性读取四个方面进行了简单的分析。虽然Kestrel已成为历史，但是其中memcached网络模型、libevent异步事件处理库等知识点还是很值得去学习和思考的。另推荐一篇对memcached源码分析写的非常不错的系列博客。Memcached源码分析","categories":[{"name":"技术","slug":"技术","permalink":"https://geminiguy.github.io/categories/技术/"}],"tags":[{"name":"Kestrel","slug":"Kestrel","permalink":"https://geminiguy.github.io/tags/Kestrel/"},{"name":"memcache","slug":"memcache","permalink":"https://geminiguy.github.io/tags/memcache/"},{"name":"libevent","slug":"libevent","permalink":"https://geminiguy.github.io/tags/libevent/"},{"name":"分布式消息","slug":"分布式消息","permalink":"https://geminiguy.github.io/tags/分布式消息/"}]},{"title":"我眼中的2016年电影之最","slug":"2016-movie","date":"2017-02-05T03:33:43.000Z","updated":"2017-02-11T09:05:35.000Z","comments":true,"path":"2017/02/05/2016-movie/","link":"","permalink":"https://geminiguy.github.io/2017/02/05/2016-movie/","excerpt":"前言 初九，北京，阳光灿烂的日子。老天赏了个好脸色，仿佛在召唤村里的码农明天赶紧回来开工。隔壁老王平时比较喜欢赏片（别想歪2333），因此想趁着新的一年开工之前，再来回顾一下2016年那些经典的电影。 There are a thousand Hamlets in a thousand people’s eyes. —William Shakespeare 老莎说过，一千个人眼里就有一千个哈姆雷特。每个人都有自己喜欢的电影类型，这两年豆瓣上不乏“哈韩党”、“文艺装逼党”，高分的电影未必符合大众的审美，不一定好看。当然低分的国产电影，您也无需恼火，就像春节档上映的《西游伏妖篇》，特效还算不错，笑点还算凑合，虽然剧情烂了点，但是春节带着大朋友、小朋友们一起看看这种无厘头电影，乐呵乐呵，也是一种不错的体验，何况星爷是一位好的演员，但是从来也没有被承认过是一位好的导演和编剧。看到微博、豆瓣上面对这个片的好坏争得面红耳赤，真没这个必要。目前国内导演不是拍不出好的电影，而是意识形态所决定的，也不能全怨光腚总局，这个知乎好像有过讨论。况且你造每年美帝和棒子国也生产出很多烂片么？好片毕竟是少数。大家都这么忙，选自己喜欢的电影去消磨时间就OK啦，何必咸吃萝卜淡操心，人家吃你家一粒米啦？呵呵。哎，有点扯远了，下面就来聊聊老王眼中的2016年电影之最。","text":"前言 初九，北京，阳光灿烂的日子。老天赏了个好脸色，仿佛在召唤村里的码农明天赶紧回来开工。隔壁老王平时比较喜欢赏片（别想歪2333），因此想趁着新的一年开工之前，再来回顾一下2016年那些经典的电影。 There are a thousand Hamlets in a thousand people’s eyes. —William Shakespeare 老莎说过，一千个人眼里就有一千个哈姆雷特。每个人都有自己喜欢的电影类型，这两年豆瓣上不乏“哈韩党”、“文艺装逼党”，高分的电影未必符合大众的审美，不一定好看。当然低分的国产电影，您也无需恼火，就像春节档上映的《西游伏妖篇》，特效还算不错，笑点还算凑合，虽然剧情烂了点，但是春节带着大朋友、小朋友们一起看看这种无厘头电影，乐呵乐呵，也是一种不错的体验，何况星爷是一位好的演员，但是从来也没有被承认过是一位好的导演和编剧。看到微博、豆瓣上面对这个片的好坏争得面红耳赤，真没这个必要。目前国内导演不是拍不出好的电影，而是意识形态所决定的，也不能全怨光腚总局，这个知乎好像有过讨论。况且你造每年美帝和棒子国也生产出很多烂片么？好片毕竟是少数。大家都这么忙，选自己喜欢的电影去消磨时间就OK啦，何必咸吃萝卜淡操心，人家吃你家一粒米啦？呵呵。哎，有点扯远了，下面就来聊聊老王眼中的2016年电影之最。 2016最好看的国产犯罪片 —《湄公河行动》 根据真实事件改编的缉毒大片，对于从小喜欢玩CS的我来说，整部电影燃到爆，肾上腺素爆表，爱国情怀爆棚。主旋律又如何，个人英雄主义又如何，美帝好莱坞不也是玩的也666么，例如《萨里机长》，看不惯国产电影中有这些元素的人真是被惯出来的。最后向缉毒警察致敬，感动！ 2016年最好看的荒诞喜剧 —《驴得水》 这是一部透露着悲剧色彩，处处充满讽刺的喜剧电影。影片中的每一位人物的性格都非常鲜明，也代表了那个年代中国的阶层背景。这部电影也可以解读为女权主义者的呐喊，对于性解放的抗争。豆瓣、知乎对于这部电影已经有非常多好的影评了，就不再班门弄斧了。这部电影的主题曲《我要你》真是唱的心痒痒呦。任素汐饰演的张一曼没的说，好演员不看颜值，赞！ 在知乎看到该片的导演编剧周申谈起这部影片，说从开始做到最后做成经历了7年的时间，一度困难重重，期间对于作品的追求让他们也拒绝了很多投资，一个靠谱的项目遇到了两个不靠谱的人，哈哈，最终周申和刘露坚守住了作品的底线，完成了一部艺术与商业兼修的好片，服！ 2016年最好看的国外战争片 —《比利·林恩的中场战事》 李安导演的在这一部电影中运用了新的拍摄技术，4K+120帧+3D，当时在电影院看这部片的时候应该不是120帧的，因此对于120帧到底牛逼在哪里，遗憾没能体会到。这张剧照非常有意思，这位大男孩回家了，他是一位英雄，有家人和佳人相伴，回到战场，是一名士兵，要忍受炮火和战友的牺牲。这位大男孩孤独的靠在墙边，这一天中各种画面在脑海中闪现，第一人称的视角也更具有带入感。他的故事，你懂了吗？愿世界和平！ 2016年最好看的动画片 —《疯狂动物城》 长大了，看动画片的次数就少了很多，16年最好看的动画片还是从众一下，给了这部迪士尼的片子。里面一些梗还记忆犹新，比如树懒的慢动作好想打他额，还有教父的经典片段COS，哈哈，像经典致敬，不错。各个方面都是一部不容错过的动画片。 2016年最好看的灾难片 —《釜山行》 2016这一年好看的韩国电影倒不少，例如《釜山行》《隧道》《小姐》等等，谈到灾难恐怖片，不得不提到这部《釜山行》，一部恐怖片里最可怕的是不是丧尸的恐怖，而是人性的丧失，例如上层官员对于真相的掩盖以及责任的逃避，那位大叔非常恶心的自私嘴脸等等，当然，影片中年轻小伙为了陪伴女友宁愿被咬死，大叔为了保护怀孕的妻子壮烈牺牲，石宇从最初的比较自私到最后牺牲自己拯救他人以及自己女儿的行为，都让人感动。最后士兵难道不能放空一枪么，晕…..一部僵尸片透露出这么多的内容，还是很值得国产恐怖片深思的，距离还有很远。 最后为啥老想到那句话，明知山有虎(釜)，偏向虎（釜）山行，额…… 2016年最好看的情色片 —《小姐》 作为一部同性片来看，先不说里面透露的深层含义，女权主义。连阅片无数的隔壁老王，看这部电影的时候，都无耻的硬了好几次，（捂脸逃……），朴赞郁真是个会讲故事的肮脏老头子呀，污的优雅，谁看谁知道，嘿嘿嘿 2016年最好看的励志片 —《垫底辣妹》 这片其实15年就已经在岛国上映，16年4月份才在大陆上映，讲述了一位漂亮的小姐姐不正干，在班里倒数垫底，中间被坪田老湿调教，发现自己还蛮有潜力的呢，带着她妈的亲情光环，闺蜜同学友情加持，绝地逆袭，考取了庆应大学文学系（还好不考数学啊…..），以大多数人的努力程度之低，根本轮不到去拼天赋，嗯哼，实属鸡汤励志电影佳作。其实还有一部《飞鹰艾迪》也是16年的励志好片，但是谁让爱学习的小姐姐这么漂酿清纯呢，就选你了~~ 2016年最好看的科幻片 —《奇异博士》 这一年的科幻大作不少，例如《奇异博士》、《X战警:天启》、《魔兽》、《美国队长3》、《死侍》等等。视觉特效没得说，大爱卷福，漫威动漫改编的电影，其中很多彩蛋关联也是看了影评才了解，纯商业大片，不知道再说些啥了，老司机开车不要玩手机啊2333。欢迎doctor加入复仇者联盟，不知道会不会出现在第三部系列作品当中呢？ 2016年最好看的历史传记片 —《斯诺登》 说起历史传记片，高分片非常多，但是这一年这种题材的片子看的少且我也比较俗，就选了一部最贴近生活的。棱镜事件确实非常震惊，其实美帝监听邮件、电话、聊天记录那一套，其他国家未必不存在。这部电影是把“爱国者”与公民隐私权的对立面放大了，事物均有两面性，还是值得深思的。影片中斯诺登的扮演者演技出众，IT屌丝气质与geek气质完美。最后也提醒大家在日常生活中多注意自己的隐私安全。 2016年最好看的爱情片 —《你的名字》 2016爱情片看的是最少的，感情不算顺利，期待2017年你的名字出现吧，哈哈，（逃 总结祝愿2017年涌现出更多的优秀国产片，单靠卖情怀，消费粉丝的ip电影少赚点钱吧（虽然不太可能，呵呵）。Whatever，明天开工大吉！","categories":[{"name":"电影","slug":"电影","permalink":"https://geminiguy.github.io/categories/电影/"}],"tags":[{"name":"电影","slug":"电影","permalink":"https://geminiguy.github.io/tags/电影/"},{"name":"2016","slug":"2016","permalink":"https://geminiguy.github.io/tags/2016/"}]},{"title":"Kafka Controller","slug":"Kafka-Controller","date":"2017-01-12T16:00:00.000Z","updated":"2017-01-17T09:33:27.000Z","comments":true,"path":"2017/01/13/Kafka-Controller/","link":"","permalink":"https://geminiguy.github.io/2017/01/13/Kafka-Controller/","excerpt":"前言目前网上针对Kafka Controller的分析文章不算少，但是大多比较散乱，不够系统，因此趁着这次部门分享Kafka的机会，将一些知识点进行了梳理总结，学习过程中参考了一些原理性的分析文章和0.10版本的源码。本文埋了一些细节坑，待有时间再回来补全吧。对于Kafka的研究水平有限，如果文章中出现错误，还望在评论区交流指正，谢谢。下面我们首先从基础概念开始讲起。","text":"前言目前网上针对Kafka Controller的分析文章不算少，但是大多比较散乱，不够系统，因此趁着这次部门分享Kafka的机会，将一些知识点进行了梳理总结，学习过程中参考了一些原理性的分析文章和0.10版本的源码。本文埋了一些细节坑，待有时间再回来补全吧。对于Kafka的研究水平有限，如果文章中出现错误，还望在评论区交流指正，谢谢。下面我们首先从基础概念开始讲起。 基础概念 什么是Controller： 从Kafka集群中选取一个broker作为controller，负责管理topic分区和副本的状态的变化，以及执行重分配分区之类的管理任务。 Replication总共经历了三个版本的迭代，其优点如下： 解决了Zk的split-brain问题，分区状态的一致性得到保障 更少的ZK监听器，减轻了Zk负载以及herd effect问题 Leader的变化针对Zk的读写可以批量操作，减少failover过程中的延迟 Controller将状态的改变直接通过RPC的方式通知相应broker，相比ZK队列方式更高效 名词解释 AR 当前已分配的副本列表 RAR 重分配过的副本列表 ORA 重分配之前的副本列表 分区Leader 给定分区负责客户端读写的结点 ISR “in-sync” replicas，能够与Leader保持同步的副本集合（Leader也在ISR中） 和controller相关的zookeeper路径说明 /controller：结点存放当前Controller信息 /brokers/ids/[brokerId]：存放集群broker信息，包括ip、端口、jmx信息 /brokers/topics：子目录为topic列表 /brokers/topics/[topic]：存放对应topic的各个分区AR /brokers/topics/[topic]/partitions/[partitionId]/state：结点存放当前topic各个分区的Leader、ISR、controller_epoch、leader_epoch等信息。 /admin临时结点，只有相关操作时才会存在 /admin/delete_topics： 要删除的一些topic /admin/reassign_partitions：指导重新分配AR的路径，通过命令修改AR时会写入到这个路径下 /admin/preferred_replica_election：分区需要重新选举第一个replica作为leader，即preferred replica。起到自动平衡Leader分配的作用，使用自带工具或者auto.leader.rebalance.enable=true均可 LeaderAndIsrRequest,UpdateMetadataRequest,StopReplicaRequestLeaderAndIsrRequest请求及响应123456789101112131415161718192021222324/*** controllerId：controller所在的brokerId* controllerEpoch：controller选举版本号* partitionStates：Map[(topic, partitionId), PartitionState]* liveLeaders：传入参数分区leader所在的broker集合*/public LeaderAndIsrRequest(int controllerId, int controllerEpoch, Map&lt;TopicPartition, PartitionState&gt; partitionStates,Set&lt;Node&gt; liveLeaders) &#123;...&#125;/*** controllerEpoch：controller选举版本号* leader：分区leader所在的broker Id* leaderEpoch：分区leader选举版本号* isr：当前ISR列表* zkVersion：分区在zookeeper上的状态信息，用作竞态更新* replicas：分区副本列表*/public PartitionState(int controllerEpoch, int leader, int leaderEpoch, List&lt;Integer&gt; isr, int zkVersion, Set&lt;Integer&gt; replicas) &#123; this.controllerEpoch = controllerEpoch; this.leader = leader; this.leaderEpoch = leaderEpoch; this.isr = isr; this.zkVersion = zkVersion; this.replicas = replicas;&#125; 请求响应流程：makeLeaders、makeFollowers具体逻辑留坑待填 UpdateMetadataRequest请求及响应12345678/*** 可以看到此构造函数和LeaderAndIsrRequest请求类构造函数参数基本一致* liveBrokers：存活的broker集合*/public UpdateMetadataRequest(int version, int controllerId, int controllerEpoch, Map&lt;TopicPartition, PartitionState&gt; partitionStates, Set&lt;Broker&gt; liveBrokers)请求响应：每个broker都维护了相同的缓存，更新MetadataCache实例中的chace字段和aliveBroker字段分别为topic对应的分区状态信息以及当前可用的broker列表 StopReplicaRequest请求及响应1234public StopReplicaRequest(int controllerId, int controllerEpoch, boolean deletePartitions, Set&lt;TopicPartition&gt; partitions)请求响应：1. ReplicaManager会移除replica所在的partition的Fetcher，即不再向该partition的leader拉取新的数据2. 再根据deletePartitions决定是否删除该replica对应的topic partition日志 Partition状态机 PartitionState四种分区状态如下： NonExistentPartition：该分区要么没有被创建过或曾经被创建过但后面删除了 NewPartition：分区创建之后已经分配了副本，但是还没有选举出Leader和ISR OnlinePartition：分区Leader一旦被选举出来，就处在该状态 OfflinePartition：如果leader选举出来后，leader broker宕机了，那么该分区就处于OfflinePartition状态 分区状态转换图针对OnlinePartition,OfflinePartition –&gt; OnlinePartition而言，有四种Leader选举器策略如下: OfflinePartitionLeaderSelector If at least one broker from the isr is alive, it picks a broker from the live isr as the new leader and the live isr as the new isr. Else, if unclean leader election for the topic is disabled, it throws a NoReplicaOnlineException. Else, it picks some alive broker from the assigned replica list as the new leader and the new isr. If no broker in the assigned replica list is alive, it throws a NoReplicaOnlineException Replicas to receive LeaderAndIsr request = live assigned replicas，Once the leader is successfully registered in zookeeper, it updates the allLeaders cache ReassignedPartitionLeaderSelector New leader = a live in-sync reassigned replicaNew isr = current isrReplicas to receive LeaderAndIsr request = reassigned replicas PreferredReplicaPartitionLeaderSelector New leader = preferred (first assigned) replica (if in isr and alive)New isr = current isrReplicas to receive LeaderAndIsr request = assigned replicas ControlledShutdownLeaderSelector New leader = replica in isr that’s not being shutdownNew isr = current isr - shutdown replicaReplicas to receive LeaderAndIsr request = live assigned replicas Replica状态机 ReplicaState副本状态如下： NewReplica：当创建了topic或者重分配分区时Controller会创建新的副本，就处在这个状态，此状态中的副本只能接收“成为follower”的状态变更请求，可由NonExistentReplica转换而来 OnlineReplica：一旦启动了一个副本以及该分区AR副本集合中的一部分，那么就将设置该副本状态为OnlineReplica。在此状态中的副本可以接收”成为leader”或”成为follower”的状态变更请求。可由NewRelica、OnlineReplica或OfflineReplica状态转换而来 OfflineReplica：如果一个副本挂掉(保存该副本的broker宕机)将被置于OfflineReplica状态，可由NewReplica或OnlineReplica状态转换而来 ReplicaDeletionStarted：开启副本删除操作时会将副本状态置于ReplicaDeletionStarted状态，可由OfflineReplica状态转换而来 ReplicaDeletionSuccessful：如果副本删除请求成功，返回的响应没有错误的话，该副本会被置于ReplicaDeletionSuccessful状态，可由ReplicaDeletionStarted状态转换而来 ReplicaDeletionIneligible：如果副本删除失败，将被置于ReplicaDeletionIneligible状态，可由ReplicaDeletionStarted状态转换而来 NonExistentReplica：如果副本被成功删除将被置于NonExistentReplica状态，可由ReplicaDeletionSuccessful状态转换而来 副本状态转换图 举例分析创建topic 命令行逻辑 12345bin/kafka-topics.sh --zookeeper XXX:12181 --create --topic fanstop_messagecore --partitions 2 --replication-factor 3a.确定分区副本的分配方案0 --&gt; [2,1,3]1 --&gt; [3,2,4]b.创建Zk结点，将分配方案写到 /brokers/topics/fanstop_messagecore 结点下 Controller后台逻辑 Controller启动时,分区状态机PartitionStateMachine.registerListeners()会注册一些监听器，当用命令行新增加了/brokers/topics/fanstop_messagecore结点后，就会触发监听器TopicChangeListener的handleChildChange方法，逻辑如下： 获取/brokers/topics路径下集合，与当前controller中保存的topic集合比较，找出新增topic集合，比如fanstop_messagecore（新增or删除） 更新controller的topic缓存列表 从/brokers/topics/fanstop_messagecore结点取出这个topic所有分区的分配方案，更新controller对应的缓存信息 调用KafkaController.onNewTopicCreation方法 onNewTopicCreation 123456def onNewTopicCreation(topics: Set[String], newPartitions: Set[TopicAndPartition]) &#123; info(\"New topic creation callback for %s\".format(newPartitions.mkString(\",\"))) // subscribe to partition changes topics.foreach(topic =&gt; partitionStateMachine.registerPartitionChangeListener(topic)) onNewPartitionCreation(newPartitions)&#125; 为每一个topic注册/brokers/topics/[topic]/下的分区变更监听器PartitionModificationsListener，本次仅注册但不会触发 调用onNewPartitionCreation方法创建分区 onNewPartitionCreation 1234567def onNewPartitionCreation(newPartitions: Set[TopicAndPartition]) &#123; info(\"New partition creation callback for %s\".format(newPartitions.mkString(\",\"))) partitionStateMachine.handleStateChanges(newPartitions, NewPartition) replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), NewReplica) partitionStateMachine.handleStateChanges(newPartitions, OnlinePartition, offlinePartitionSelector) replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), OnlineReplica)&#125; 创建新增分区对象，分区状态机将新创建分区转变为NewPartition状态 从Controller缓存中取出新增分区的副本分配方案，针对每一个replica进行NonExistentReplica–&gt; NewReplica状态转换 分区状态 NewPartition–&gt;OnlinePartition，调用initializeLeaderAndIsrForPartition(topicAndPartition)为新分区初始化leader和isr路径。主要策略就是让AR中第一个replica作为leader，所有可用的replica作为ISR，将leader、ISR、leaderepoch、controllerepoch、zkversion等信息写入Zk state节点，ControllerContext更新相应topic分区的leader和ISR缓存。之后就是发送LeaderAndIsrRequest给每个replica和UpdateMetadataRequest请求给每个可用的broker 设置副本状态机状态NewReplica—&gt;OnlineReplica，将当前的replica加入到controllerContext AR缓存中。完事…… Broker Failure下面来分析一下某台broker宕机的情况。 broker宕机后，zk会话超时，/brokers/ids对应结点被删除，触发BrokerChangeListener.handleChildChange，接着又调用controller.onBrokerFailure方法， 对Leader副本在deadBroker上的分区（同时要排除topic在删除的状态）触发OfflinePartition状态转换 这一步就是为处于OfflinePartition状态的分区触发OnlinePartition状态转换，ok，还记得上面提到的OfflinePartitionLeaderSelector选举器吧，这回就用它来进行Leader选举、ISR重分配，以及选出接收LeaderAndIsr请求的replica。更新一下Zk state结点的leader和ISR相关信息，更新controllerContext的leader缓存，给相应broker发送LeaderAndIsrRequest请求，顺带发送UpdateMetadataRequest请求，这些动作都是在electLeaderForPartition函数中完成 找出deadBroker上的所有副本，并且要过滤掉一些topics正在执行删除操作的replica，副本状态机执行OfflineRelica状态转换，过程不再赘述 check出正在执行topic删除期间的replica，将这些replica置为ReplicaDeletionIneligible，这些replica在broker down的时候是不能被删除的。 分区副本重新分配策略Kafka提供了分区重新分配的工具，在生产环境下，随着负载的增大，可能需要给Kafka集群扩容，但是对于已存在的topic，并不会自动将分区的副本迁移到新的Broker上，就可以用到这个工具。除此之外，我们还可以用这个工具来调整分区的AR数量，下面就来说一下Partition方案重新分配的情况，也涉及Controller非常重要的一个方法：onPartitionReassignment。当用命令行发起分区重分配操作时，它会在/admin/reassign_partitions路径下创建节点，进而触发PartitionsReassignedListener监听器，执行handleDataChange函数，过滤掉正在执行重分配的副本的分区，接着判断它们的topic是否正在进行删除，构造一个ReassignedPartitionsContext传递给controller.initiateReassignReplicasForTopicPartition为给定topic分区重新分配副本，这个函数的逻辑看了下源码，基本流程如下： 取出controllerContext针对这个分区的AR缓存，当前AR和RAR集合完全一样的的话，抛异常，不用重分配了 否则，判断一下RAR中是否存在不可用的副本，如果存在replica not alive，抛异常，此次重分配操作无法进行 如果RAR中均可用，注册Zk state结点的listen，监听ISR变化，mark一下该topic不能被删除。 最后一步调用最重要的函数onPartitionReassignment开始重新分配分区的副本 onPartitionReassignment这里我们还是以源码中的例子来说明整个流程:OAR = {1,2,3}RAR = (4,5,6) AR(Zk) leader/isr(Zk) transition {1,2,3} 1/{1,2,3} (initial state) {1,2,3,4,5,6} 1/{1,2,3} (step 2) {1,2,3,4,5,6} 1/{1,2,3,4,5,6} (step 4) {1,2,3,4,5,6} 4/{1,2,3,4,5,6} (step 7) {1,2,3,4,5,6} 4/{4,5,6} (step 8) {4,5,6} 4/{4,5,6} (step 10) 总结本文只举了三个经典的例子，后面再慢慢扩充用到Controller的实例分析吧。对于之前连Scala语法都没接触过的老王来说，整个调研学习过程真可谓折磨蛋疼额，技术无止境，共勉吧。However，还是希望本文能对读者有所帮助。 参考文献 官方wiki：Kafka Controller Internals 推荐Kafka相关博客 Kafka Controller源码分析","categories":[{"name":"技术","slug":"技术","permalink":"https://geminiguy.github.io/categories/技术/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://geminiguy.github.io/tags/Kafka/"},{"name":"Kafka Controller","slug":"Kafka-Controller","permalink":"https://geminiguy.github.io/tags/Kafka-Controller/"},{"name":"源码分析","slug":"源码分析","permalink":"https://geminiguy.github.io/tags/源码分析/"}]},{"title":"Hello World","slug":"index","date":"2016-12-31T16:00:00.000Z","updated":"2017-01-14T09:27:00.000Z","comments":true,"path":"2017/01/01/index/","link":"","permalink":"https://geminiguy.github.io/2017/01/01/index/","excerpt":"","text":"Hello world，隔壁老王新的一年博客开张个人比较懒，平时知识点也只是随手记录在印象笔记希望这一年能多写一些技术文章吧Whatever，新年快乐Ps：Hexo的环境配置真是好多坑啊，还是比较喜欢NexT这个主题","categories":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/categories/闲聊/"}],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/tags/闲聊/"}]}]}