{"meta":{"title":"隔壁老王的Blog","subtitle":null,"description":"嘘，要发车了","author":"Gemini","url":"https://geminiguy.github.io"},"pages":[{"title":"categories","date":"2017-01-14T09:04:41.000Z","updated":"2017-01-14T09:12:51.000Z","comments":false,"path":"categories/index.html","permalink":"https://geminiguy.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-01-14T05:54:18.000Z","updated":"2017-01-14T06:02:54.000Z","comments":false,"path":"tags/index.html","permalink":"https://geminiguy.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"Note-2017-02-18","date":"2017-02-18T15:44:39.000Z","updated":"2017-02-18T15:46:26.000Z","comments":true,"path":"2017/02/18/Note-2017-02-18/","link":"","permalink":"https://geminiguy.github.io/2017/02/18/Note-2017-02-18/","excerpt":"title: 周六杂记壹贰叁date: 2017-02-18tags: [闲聊,美食] categories: 闲聊杂记壹 回顾这一周，好像都在应付各种小项目开发，粉条2017年改版大项目启动，设计评审会加各种对接口格式又是两天的时间。用来学习基础jvm知识的时间大大被压榨，买的《人类简史》和《未来简史》也沉睡了好几天。However，最重要的是，我的锅也沉睡许久，是时候唤醒它了~~","text":"title: 周六杂记壹贰叁date: 2017-02-18tags: [闲聊,美食] categories: 闲聊杂记壹 回顾这一周，好像都在应付各种小项目开发，粉条2017年改版大项目启动，设计评审会加各种对接口格式又是两天的时间。用来学习基础jvm知识的时间大大被压榨，买的《人类简史》和《未来简史》也沉睡了好几天。However，最重要的是，我的锅也沉睡许久，是时候唤醒它了~~ 之前设想的是每周都学做一道新菜，不仅是因为我司食堂太难吃，也是让自己的码农生活不要过得太屌丝吧，多一些正能量，或许就成了程序猿界的“厨神”了呢？😁 周六早上反而睡不久了，于是乎起床买菜，在超市里看到了新鲜的湿面，这是个悲剧的前戏…… 人生不只有苟且的工作，还有眼前的凉拌花生米和辣子鸡 杂记贰 下午看了会《未来简史》，睡了一觉醒来六点多了。晚饭吃点啥呢？凉拌花生米没有吃完，干脆下早上买的湿面吧，悲剧开始了…… 内心OS：好想拿刀砍了这湿面 杂记叁 晚上一个也住在附近的师弟要过来找我谈心，我的煮面小奶锅毁了，我也要出去散散心，😶，出去溜了一圈，果然有收获，见图。 一辆废弃的加长林肯，孤独的守候在五环外的马路边，“辽”字车牌隐约可见。这位东北大哥曾经的辉煌，你读懂了吗？ 杂记终最后以《乘风破浪》里的一句经典台词作为这篇毫无逻辑的杂记文章的结尾吧。 我的梦想，歌舞厅里只唱歌，桑拿馆里就洗澡！ 还有一首非常好听的歌曲推荐，500 Miles，晚安，好梦~~","categories":[],"tags":[]},{"title":"Ckestrel框架浅析","slug":"ckestrel框架浅析","date":"2017-02-11T16:00:00.000Z","updated":"2017-02-12T07:40:58.000Z","comments":true,"path":"2017/02/12/ckestrel框架浅析/","link":"","permalink":"https://geminiguy.github.io/2017/02/12/ckestrel框架浅析/","excerpt":"概述 Kestrel是一个利用Scala语言编写的轻量级消息队列，由Twitter团队开源，其支持三种协议：memcache、thrift、text。Kestrel具有高性能、代码轻量级、持久存储（记录读写日志到journal）、可靠性（支持可靠获取）等优点。而本文所要说的Ckestrel是Kestrel的C++版本，由团队的老前辈改版而成，采用的协议是memcached文本协议。由于吞吐量、稳定性、代码维护性等等原因满足不了业务需求，因此逐步会被Kafka取而代之。这篇文章是我15年刚入职那会调研学习这个框架的源码所写的wiki，现照搬到我的博客上面。本文将对Ckestrel的线程模型及状态机、持久化日志和可靠性读取机制等方面做相关分析。","text":"概述 Kestrel是一个利用Scala语言编写的轻量级消息队列，由Twitter团队开源，其支持三种协议：memcache、thrift、text。Kestrel具有高性能、代码轻量级、持久存储（记录读写日志到journal）、可靠性（支持可靠获取）等优点。而本文所要说的Ckestrel是Kestrel的C++版本，由团队的老前辈改版而成，采用的协议是memcached文本协议。由于吞吐量、稳定性、代码维护性等等原因满足不了业务需求，因此逐步会被Kafka取而代之。这篇文章是我15年刚入职那会调研学习这个框架的源码所写的wiki，现照搬到我的博客上面。本文将对Ckestrel的线程模型及状态机、持久化日志和可靠性读取机制等方面做相关分析。 CKestrel线程模型及状态机线程模型 Ckestrel采用了memcached的线程模型来处理网络连接，而memcached使用libevent实现异步服务器，采用主线程和worker线程，主线程负责监听网络连接，并且accept连接。当监听到连接时，accept连接成功后，把相应的client fd丢给其中一个worker线程。worker线程接收主线程丢过来的client fd，加入到自己的epoll监听队列，负责处理该连接的读写事件。memcached的线程模型图如下所示： 主线程通过evnet_init()为自己分配一个event_base，用于监听连接，即listen fd。 主线程创建n个worker线程，同时每个worker线程也分配了独立的event_base。每个worker线程通过管道方式与主线程进行通信，调用pipe函数，产生两个fd，一个是管道写入fd（notify_send_fd），一个是管道读取fd（notify_receive_fd）。worker线程把管道读取fd（notify_receive_fd）加到自己的event_base，监听管道读取fd的可读事件，即当主线程往某个线程的管道写入fd写数据时，触发事件。 主线程监听到有一个连接到达时，accept连接，产生一个client fd，然后选择一个worker线程，把这个client fd包装成一个CQ_ITEM对象（其中不仅有client fd参数，还包括init_state、event_flags、read_buffer_size等参数）然后压到worker线程的CQ_ITEM队列里面去（每个worker线程有一个CQ_ITEM队列），同时主线程往选中的worker线程的管道写入fd中写入一个字符“c”（Ckestrel中写入””，用来触发worker线程）。 某个worker线程监听到自己的管道读取fd可读，触发事件处理函数thread_libevent_process，从CQ_ITEM队列中取出CQ_ITEM对象，调用conn_new函数把此client fd加入到自己的event_base中，从此负责该连接的读写工作。 状态机 主线程和worker线程都调用conn_new函数进行事件监听，有事件发生时调用event_handler函数，最终执行driver_machine函数。状态机drive_machine函数是worker线程处理网络请求业务的逻辑核心。while循环中包含switch case，根据连接对象conn的当前连接状态state进入不同的case，每个case可能会改变conn对象的连接状态，进而被分发到合适的case上进行处理，最终由stop=true的case分支退出while循环。详细的解析请参考Memcached源码分析之请求处理。 Ckestrel持久化日志 Ckestrel日志文件是唯一在硬盘存储队列内容的方式，日志文件中顺序记录每个针对相应队列的添加和删除操作。每种操作有对应的flag来记录日志类型，flag总共有以下几种：CMD_ADD、CMD_ADDX、CMD_ADD_XID、CMD_REMOVE、CMD_REMOVE_TENTATIVE、CMD_SAVE_XID、CMD_UNREMOVE、CMD_CONFIRM_REMOVE。其中CMD_ADDX和CMD_ADDXID操作会利用自定义的pack压缩方式将某条队列消息的length、xid、addTime、expiry、data等信息写入日志文件中。Ckestrel服务器启动时，对每个队列的日志文件执行replayJournal操作，重新建立内存中的队列以便客户端访问。这种方式保证了即使服务器崩溃，也能根据每个队列的日志文件重建内存中的队列消息。 Ckestrel框架在对journal处理上与目前scala 2.4.1版本上有些区别。Journal.cc中实现了roll机制对日志文件进行压缩。在PersistentQueue.cc中的add方法中： 1234567891011if (keepJournal_ &amp;&amp; !journal_-&gt;inReadBehind()) &#123; if (journal_-&gt;size() &gt; maxJournalSize_ * maxJournalOverflow_ &amp;&amp; queueSize_ &lt; maxJournalSize_) &#123; slog_write(LL_NOTICE, \"Rolling journal file for '%s' (qsize=%d)\", name_.c_str(), queueSize_); deque&lt;QItem *&gt; q = openTransactionQItems(); journal_-&gt;roll(xidCounter_, q, queue_); &#125; if (queueSize_ &gt;= maxMemorySize_) &#123; slog_write(LL_NOTICE, \"Dropping to read-behind for queue '%s' (%lu bytes)\", name_.c_str(), queueSize_); journal_-&gt;startReadBehind(); &#125; &#125; 利用kestrel.conf配置文件设置 maxJournalSize = 16M，maxJournalOverflow = 10，maxMemorySize = 128M。初始向队列写入数据时，journal不会进入ReadBehind模式。当日志文件大小大于maxJournalSize * maxJournalOverflow并且队列大小小于maxJournalSize时，journal进行roll操作，重新建立日志文件，将内存中的队列消息add进journal_日志中，其中利用pack编码方式，opcode=CMD_ADDX。同样将openTransactionQItems中未完成的事务记录在对应日志当中。 当队列大小大于等于maxMemorySize_时，启动ReadBehind模式，后面写入队列的消息将会存储在日志文件中，每当从内存中remove掉消息的时都会尝试从日志文件中读取相关队列消息再pushback到内存队列中，这种状态一直持续到reader和writer_指针重合，即在ReadBehind模式下add进日志文件的消息均被处理完毕，退出ReadBehind模式。 另外在PersistentQueue.cc中remove方法中，当if (queueLength == 0 &amp;&amp; journal -&gt;size() &gt;= maxJournalSize_)时，也会对日志文件进行roll操作。 可靠性读取 默认的GET并没有加入可靠性读取选项，从队列中获取消息后，server端就将该消息从队列中移除，如果客户端在处理这个消息的时候异常崩溃或者在接收消息时连接断开，则该条队列数据就会永久丢失，而之前出现的RIN数据丢失问题则出现在这里。这种默认的方式是不安全的，因此Kestrel提供了可靠性读取机制，在GET命令中加入/open和/close选项。官方文档对/open和/close的描述如下： /openTentatively remove an item from the queue. The item is returned as usual but is also set aside in case the client disappears before sending a “close” request. /closeClose any existing open read. 当在消费机客户端GET命令中使用/open时，kestrel服务器将这个消息从队列暂时移除并正常发送给消费机客户端，同时在openTransactions这个map容器中备份该队列数据，如果这时候客户端崩溃或者断开连接，从openTransactions中根据xid键取出该队列数据，重新放入内存队列头部，因此当客户端重新连接后就可以获取到该队列消息。每个连接的client只能有一个正在执行的可靠获取，再次发送带有/open选项的GET命令server返回空（同一个连接直接发送GET命令也会返回空）。当消费机客户端收到该队列数据时，再次发送带/close选项的GET命令，server将会confirmRemove该队列数据，从openTransactions_容器中删除这条队列数据，并在日志文件中记录CMD_CONFIRM_REMOVE。 具体分析发送完带/open选项的GET命令后，消费机与队列机服务器断开连接，则进入Ckestrel.cc中的conn_close函数，执行qc-&gt;unremove操作。 12345678static void conn_close(conn *c)&#123; if (c-&gt;xid) &#123; if (qc-&gt;unremove(std::string(c-&gt;xkey, c-&gt;xnkey), c-&gt;xid) == false) &#123; slog_write(LL_WARNING, \"Unremove non-existent transaction\"); &#125; c-&gt;xid = 0; &#125;&#125; 最终进入PersistentQueue.cc的doUnremove函数，在openTransactions_容器中根据上一条队列消息的xid找到该item，再pushfront到内存队列头部，在openTransactions容器中删除该队列消息。客户端重新连接到服务器后，就可以从服务器内存队列中取到该条队列消息，这就是kestrel的可靠读取机制的实现。 123456789101112bool PersistentQueue::doUnremove(int xid) &#123; map&lt;int, QItem*&gt;::iterator it = openTransactions_.find(xid); if (it != openTransactions_.end()) &#123; queueLength_ += 1; queueSize_ += it-&gt;second-&gt;getLength(); queue_.push_front(it-&gt;second); memoryBytes_ += it-&gt;second-&gt;getLength(); openTransactions_.erase(it); return true; &#125; return false;&#125; 总结 本文从Kestrel的线程模型、状态机、持久化日志、可靠性读取四个方面进行了简单的分析。虽然Kestrel已成为历史，但是其中memcached网络模型、libevent异步事件处理库等知识点还是很值得去学习和思考的。另推荐一篇对memcached源码分析写的非常不错的系列博客。Memcached源码分析","categories":[{"name":"技术","slug":"技术","permalink":"https://geminiguy.github.io/categories/技术/"}],"tags":[{"name":"Kestrel","slug":"Kestrel","permalink":"https://geminiguy.github.io/tags/Kestrel/"},{"name":"memcache","slug":"memcache","permalink":"https://geminiguy.github.io/tags/memcache/"},{"name":"libevent","slug":"libevent","permalink":"https://geminiguy.github.io/tags/libevent/"},{"name":"分布式消息","slug":"分布式消息","permalink":"https://geminiguy.github.io/tags/分布式消息/"}]},{"title":"我眼中的2016年电影之最","slug":"2016-movie","date":"2017-02-05T03:33:43.000Z","updated":"2017-02-11T09:05:35.000Z","comments":true,"path":"2017/02/05/2016-movie/","link":"","permalink":"https://geminiguy.github.io/2017/02/05/2016-movie/","excerpt":"前言 初九，北京，阳光灿烂的日子。老天赏了个好脸色，仿佛在召唤村里的码农明天赶紧回来开工。隔壁老王平时比较喜欢赏片（别想歪2333），因此想趁着新的一年开工之前，再来回顾一下2016年那些经典的电影。 There are a thousand Hamlets in a thousand people’s eyes. —William Shakespeare 老莎说过，一千个人眼里就有一千个哈姆雷特。每个人都有自己喜欢的电影类型，这两年豆瓣上不乏“哈韩党”、“文艺装逼党”，高分的电影未必符合大众的审美，不一定好看。当然低分的国产电影，您也无需恼火，就像春节档上映的《西游伏妖篇》，特效还算不错，笑点还算凑合，虽然剧情烂了点，但是春节带着大朋友、小朋友们一起看看这种无厘头电影，乐呵乐呵，也是一种不错的体验，何况星爷是一位好的演员，但是从来也没有被承认过是一位好的导演和编剧。看到微博、豆瓣上面对这个片的好坏争得面红耳赤，真没这个必要。目前国内导演不是拍不出好的电影，而是意识形态所决定的，也不能全怨光腚总局，这个知乎好像有过讨论。况且你造每年美帝和棒子国也生产出很多烂片么？好片毕竟是少数。大家都这么忙，选自己喜欢的电影去消磨时间就OK啦，何必咸吃萝卜淡操心，人家吃你家一粒米啦？呵呵。哎，有点扯远了，下面就来聊聊老王眼中的2016年电影之最。","text":"前言 初九，北京，阳光灿烂的日子。老天赏了个好脸色，仿佛在召唤村里的码农明天赶紧回来开工。隔壁老王平时比较喜欢赏片（别想歪2333），因此想趁着新的一年开工之前，再来回顾一下2016年那些经典的电影。 There are a thousand Hamlets in a thousand people’s eyes. —William Shakespeare 老莎说过，一千个人眼里就有一千个哈姆雷特。每个人都有自己喜欢的电影类型，这两年豆瓣上不乏“哈韩党”、“文艺装逼党”，高分的电影未必符合大众的审美，不一定好看。当然低分的国产电影，您也无需恼火，就像春节档上映的《西游伏妖篇》，特效还算不错，笑点还算凑合，虽然剧情烂了点，但是春节带着大朋友、小朋友们一起看看这种无厘头电影，乐呵乐呵，也是一种不错的体验，何况星爷是一位好的演员，但是从来也没有被承认过是一位好的导演和编剧。看到微博、豆瓣上面对这个片的好坏争得面红耳赤，真没这个必要。目前国内导演不是拍不出好的电影，而是意识形态所决定的，也不能全怨光腚总局，这个知乎好像有过讨论。况且你造每年美帝和棒子国也生产出很多烂片么？好片毕竟是少数。大家都这么忙，选自己喜欢的电影去消磨时间就OK啦，何必咸吃萝卜淡操心，人家吃你家一粒米啦？呵呵。哎，有点扯远了，下面就来聊聊老王眼中的2016年电影之最。 2016最好看的国产犯罪片 —《湄公河行动》 根据真实事件改编的缉毒大片，对于从小喜欢玩CS的我来说，整部电影燃到爆，肾上腺素爆表，爱国情怀爆棚。主旋律又如何，个人英雄主义又如何，美帝好莱坞不也是玩的也666么，例如《萨里机长》，看不惯国产电影中有这些元素的人真是被惯出来的。最后向缉毒警察致敬，感动！ 2016年最好看的荒诞喜剧 —《驴得水》 这是一部透露着悲剧色彩，处处充满讽刺的喜剧电影。影片中的每一位人物的性格都非常鲜明，也代表了那个年代中国的阶层背景。这部电影也可以解读为女权主义者的呐喊，对于性解放的抗争。豆瓣、知乎对于这部电影已经有非常多好的影评了，就不再班门弄斧了。这部电影的主题曲《我要你》真是唱的心痒痒呦。任素汐饰演的张一曼没的说，好演员不看颜值，赞！ 在知乎看到该片的导演编剧周申谈起这部影片，说从开始做到最后做成经历了7年的时间，一度困难重重，期间对于作品的追求让他们也拒绝了很多投资，一个靠谱的项目遇到了两个不靠谱的人，哈哈，最终周申和刘露坚守住了作品的底线，完成了一部艺术与商业兼修的好片，服！ 2016年最好看的国外战争片 —《比利·林恩的中场战事》 李安导演的在这一部电影中运用了新的拍摄技术，4K+120帧+3D，当时在电影院看这部片的时候应该不是120帧的，因此对于120帧到底牛逼在哪里，遗憾没能体会到。这张剧照非常有意思，这位大男孩回家了，他是一位英雄，有家人和佳人相伴，回到战场，是一名士兵，要忍受炮火和战友的牺牲。这位大男孩孤独的靠在墙边，这一天中各种画面在脑海中闪现，第一人称的视角也更具有带入感。他的故事，你懂了吗？愿世界和平！ 2016年最好看的动画片 —《疯狂动物城》 长大了，看动画片的次数就少了很多，16年最好看的动画片还是从众一下，给了这部迪士尼的片子。里面一些梗还记忆犹新，比如树懒的慢动作好想打他额，还有教父的经典片段COS，哈哈，像经典致敬，不错。各个方面都是一部不容错过的动画片。 2016年最好看的灾难片 —《釜山行》 2016这一年好看的韩国电影倒不少，例如《釜山行》《隧道》《小姐》等等，谈到灾难恐怖片，不得不提到这部《釜山行》，一部恐怖片里最可怕的是不是丧尸的恐怖，而是人性的丧失，例如上层官员对于真相的掩盖以及责任的逃避，那位大叔非常恶心的自私嘴脸等等，当然，影片中年轻小伙为了陪伴女友宁愿被咬死，大叔为了保护怀孕的妻子壮烈牺牲，石宇从最初的比较自私到最后牺牲自己拯救他人以及自己女儿的行为，都让人感动。最后士兵难道不能放空一枪么，晕…..一部僵尸片透露出这么多的内容，还是很值得国产恐怖片深思的，距离还有很远。 最后为啥老想到那句话，明知山有虎(釜)，偏向虎（釜）山行，额…… 2016年最好看的情色片 —《小姐》 作为一部同性片来看，先不说里面透露的深层含义，女权主义。连阅片无数的隔壁老王，看这部电影的时候，都无耻的硬了好几次，（捂脸逃……），朴赞郁真是个会讲故事的肮脏老头子呀，污的优雅，谁看谁知道，嘿嘿嘿 2016年最好看的励志片 —《垫底辣妹》 这片其实15年就已经在岛国上映，16年4月份才在大陆上映，讲述了一位漂亮的小姐姐不正干，在班里倒数垫底，中间被坪田老湿调教，发现自己还蛮有潜力的呢，带着她妈的亲情光环，闺蜜同学友情加持，绝地逆袭，考取了庆应大学文学系（还好不考数学啊…..），以大多数人的努力程度之低，根本轮不到去拼天赋，嗯哼，实属鸡汤励志电影佳作。其实还有一部《飞鹰艾迪》也是16年的励志好片，但是谁让爱学习的小姐姐这么漂酿清纯呢，就选你了~~ 2016年最好看的科幻片 —《奇异博士》 这一年的科幻大作不少，例如《奇异博士》、《X战警:天启》、《魔兽》、《美国队长3》、《死侍》等等。视觉特效没得说，大爱卷福，漫威动漫改编的电影，其中很多彩蛋关联也是看了影评才了解，纯商业大片，不知道再说些啥了，老司机开车不要玩手机啊2333。欢迎doctor加入复仇者联盟，不知道会不会出现在第三部系列作品当中呢？ 2016年最好看的历史传记片 —《斯诺登》 说起历史传记片，高分片非常多，但是这一年这种题材的片子看的少且我也比较俗，就选了一部最贴近生活的。棱镜事件确实非常震惊，其实美帝监听邮件、电话、聊天记录那一套，其他国家未必不存在。这部电影是把“爱国者”与公民隐私权的对立面放大了，事物均有两面性，还是值得深思的。影片中斯诺登的扮演者演技出众，IT屌丝气质与geek气质完美。最后也提醒大家在日常生活中多注意自己的隐私安全。 2016年最好看的爱情片 —《你的名字》 2016爱情片看的是最少的，感情不算顺利，期待2017年你的名字出现吧，哈哈，（逃 总结祝愿2017年涌现出更多的优秀国产片，单靠卖情怀，消费粉丝的ip电影少赚点钱吧（虽然不太可能，呵呵）。Whatever，明天开工大吉！","categories":[{"name":"电影","slug":"电影","permalink":"https://geminiguy.github.io/categories/电影/"}],"tags":[{"name":"电影","slug":"电影","permalink":"https://geminiguy.github.io/tags/电影/"},{"name":"2016","slug":"2016","permalink":"https://geminiguy.github.io/tags/2016/"}]},{"title":"Kafka Controller","slug":"Kafka-Controller","date":"2017-01-12T16:00:00.000Z","updated":"2017-01-17T09:33:27.000Z","comments":true,"path":"2017/01/13/Kafka-Controller/","link":"","permalink":"https://geminiguy.github.io/2017/01/13/Kafka-Controller/","excerpt":"前言目前网上针对Kafka Controller的分析文章不算少，但是大多比较散乱，不够系统，因此趁着这次部门分享Kafka的机会，将一些知识点进行了梳理总结，学习过程中参考了一些原理性的分析文章和0.10版本的源码。本文埋了一些细节坑，待有时间再回来补全吧。对于Kafka的研究水平有限，如果文章中出现错误，还望在评论区交流指正，谢谢。下面我们首先从基础概念开始讲起。","text":"前言目前网上针对Kafka Controller的分析文章不算少，但是大多比较散乱，不够系统，因此趁着这次部门分享Kafka的机会，将一些知识点进行了梳理总结，学习过程中参考了一些原理性的分析文章和0.10版本的源码。本文埋了一些细节坑，待有时间再回来补全吧。对于Kafka的研究水平有限，如果文章中出现错误，还望在评论区交流指正，谢谢。下面我们首先从基础概念开始讲起。 基础概念 什么是Controller： 从Kafka集群中选取一个broker作为controller，负责管理topic分区和副本的状态的变化，以及执行重分配分区之类的管理任务。 Replication总共经历了三个版本的迭代，其优点如下： 解决了Zk的split-brain问题，分区状态的一致性得到保障 更少的ZK监听器，减轻了Zk负载以及herd effect问题 Leader的变化针对Zk的读写可以批量操作，减少failover过程中的延迟 Controller将状态的改变直接通过RPC的方式通知相应broker，相比ZK队列方式更高效 名词解释 AR 当前已分配的副本列表 RAR 重分配过的副本列表 ORA 重分配之前的副本列表 分区Leader 给定分区负责客户端读写的结点 ISR “in-sync” replicas，能够与Leader保持同步的副本集合（Leader也在ISR中） 和controller相关的zookeeper路径说明 /controller：结点存放当前Controller信息 /brokers/ids/[brokerId]：存放集群broker信息，包括ip、端口、jmx信息 /brokers/topics：子目录为topic列表 /brokers/topics/[topic]：存放对应topic的各个分区AR /brokers/topics/[topic]/partitions/[partitionId]/state：结点存放当前topic各个分区的Leader、ISR、controller_epoch、leader_epoch等信息。 /admin临时结点，只有相关操作时才会存在 /admin/delete_topics： 要删除的一些topic /admin/reassign_partitions：指导重新分配AR的路径，通过命令修改AR时会写入到这个路径下 /admin/preferred_replica_election：分区需要重新选举第一个replica作为leader，即preferred replica。起到自动平衡Leader分配的作用，使用自带工具或者auto.leader.rebalance.enable=true均可 LeaderAndIsrRequest,UpdateMetadataRequest,StopReplicaRequestLeaderAndIsrRequest请求及响应123456789101112131415161718192021222324/*** controllerId：controller所在的brokerId* controllerEpoch：controller选举版本号* partitionStates：Map[(topic, partitionId), PartitionState]* liveLeaders：传入参数分区leader所在的broker集合*/public LeaderAndIsrRequest(int controllerId, int controllerEpoch, Map&lt;TopicPartition, PartitionState&gt; partitionStates,Set&lt;Node&gt; liveLeaders) &#123;...&#125;/*** controllerEpoch：controller选举版本号* leader：分区leader所在的broker Id* leaderEpoch：分区leader选举版本号* isr：当前ISR列表* zkVersion：分区在zookeeper上的状态信息，用作竞态更新* replicas：分区副本列表*/public PartitionState(int controllerEpoch, int leader, int leaderEpoch, List&lt;Integer&gt; isr, int zkVersion, Set&lt;Integer&gt; replicas) &#123; this.controllerEpoch = controllerEpoch; this.leader = leader; this.leaderEpoch = leaderEpoch; this.isr = isr; this.zkVersion = zkVersion; this.replicas = replicas;&#125; 请求响应流程：makeLeaders、makeFollowers具体逻辑留坑待填 UpdateMetadataRequest请求及响应12345678/*** 可以看到此构造函数和LeaderAndIsrRequest请求类构造函数参数基本一致* liveBrokers：存活的broker集合*/public UpdateMetadataRequest(int version, int controllerId, int controllerEpoch, Map&lt;TopicPartition, PartitionState&gt; partitionStates, Set&lt;Broker&gt; liveBrokers)请求响应：每个broker都维护了相同的缓存，更新MetadataCache实例中的chace字段和aliveBroker字段分别为topic对应的分区状态信息以及当前可用的broker列表 StopReplicaRequest请求及响应1234public StopReplicaRequest(int controllerId, int controllerEpoch, boolean deletePartitions, Set&lt;TopicPartition&gt; partitions)请求响应：1. ReplicaManager会移除replica所在的partition的Fetcher，即不再向该partition的leader拉取新的数据2. 再根据deletePartitions决定是否删除该replica对应的topic partition日志 Partition状态机 PartitionState四种分区状态如下： NonExistentPartition：该分区要么没有被创建过或曾经被创建过但后面删除了 NewPartition：分区创建之后已经分配了副本，但是还没有选举出Leader和ISR OnlinePartition：分区Leader一旦被选举出来，就处在该状态 OfflinePartition：如果leader选举出来后，leader broker宕机了，那么该分区就处于OfflinePartition状态 分区状态转换图针对OnlinePartition,OfflinePartition –&gt; OnlinePartition而言，有四种Leader选举器策略如下: OfflinePartitionLeaderSelector If at least one broker from the isr is alive, it picks a broker from the live isr as the new leader and the live isr as the new isr. Else, if unclean leader election for the topic is disabled, it throws a NoReplicaOnlineException. Else, it picks some alive broker from the assigned replica list as the new leader and the new isr. If no broker in the assigned replica list is alive, it throws a NoReplicaOnlineException Replicas to receive LeaderAndIsr request = live assigned replicas，Once the leader is successfully registered in zookeeper, it updates the allLeaders cache ReassignedPartitionLeaderSelector New leader = a live in-sync reassigned replicaNew isr = current isrReplicas to receive LeaderAndIsr request = reassigned replicas PreferredReplicaPartitionLeaderSelector New leader = preferred (first assigned) replica (if in isr and alive)New isr = current isrReplicas to receive LeaderAndIsr request = assigned replicas ControlledShutdownLeaderSelector New leader = replica in isr that’s not being shutdownNew isr = current isr - shutdown replicaReplicas to receive LeaderAndIsr request = live assigned replicas Replica状态机 ReplicaState副本状态如下： NewReplica：当创建了topic或者重分配分区时Controller会创建新的副本，就处在这个状态，此状态中的副本只能接收“成为follower”的状态变更请求，可由NonExistentReplica转换而来 OnlineReplica：一旦启动了一个副本以及该分区AR副本集合中的一部分，那么就将设置该副本状态为OnlineReplica。在此状态中的副本可以接收”成为leader”或”成为follower”的状态变更请求。可由NewRelica、OnlineReplica或OfflineReplica状态转换而来 OfflineReplica：如果一个副本挂掉(保存该副本的broker宕机)将被置于OfflineReplica状态，可由NewReplica或OnlineReplica状态转换而来 ReplicaDeletionStarted：开启副本删除操作时会将副本状态置于ReplicaDeletionStarted状态，可由OfflineReplica状态转换而来 ReplicaDeletionSuccessful：如果副本删除请求成功，返回的响应没有错误的话，该副本会被置于ReplicaDeletionSuccessful状态，可由ReplicaDeletionStarted状态转换而来 ReplicaDeletionIneligible：如果副本删除失败，将被置于ReplicaDeletionIneligible状态，可由ReplicaDeletionStarted状态转换而来 NonExistentReplica：如果副本被成功删除将被置于NonExistentReplica状态，可由ReplicaDeletionSuccessful状态转换而来 副本状态转换图 举例分析创建topic 命令行逻辑 12345bin/kafka-topics.sh --zookeeper XXX:12181 --create --topic fanstop_messagecore --partitions 2 --replication-factor 3a.确定分区副本的分配方案0 --&gt; [2,1,3]1 --&gt; [3,2,4]b.创建Zk结点，将分配方案写到 /brokers/topics/fanstop_messagecore 结点下 Controller后台逻辑 Controller启动时,分区状态机PartitionStateMachine.registerListeners()会注册一些监听器，当用命令行新增加了/brokers/topics/fanstop_messagecore结点后，就会触发监听器TopicChangeListener的handleChildChange方法，逻辑如下： 获取/brokers/topics路径下集合，与当前controller中保存的topic集合比较，找出新增topic集合，比如fanstop_messagecore（新增or删除） 更新controller的topic缓存列表 从/brokers/topics/fanstop_messagecore结点取出这个topic所有分区的分配方案，更新controller对应的缓存信息 调用KafkaController.onNewTopicCreation方法 onNewTopicCreation 123456def onNewTopicCreation(topics: Set[String], newPartitions: Set[TopicAndPartition]) &#123; info(\"New topic creation callback for %s\".format(newPartitions.mkString(\",\"))) // subscribe to partition changes topics.foreach(topic =&gt; partitionStateMachine.registerPartitionChangeListener(topic)) onNewPartitionCreation(newPartitions)&#125; 为每一个topic注册/brokers/topics/[topic]/下的分区变更监听器PartitionModificationsListener，本次仅注册但不会触发 调用onNewPartitionCreation方法创建分区 onNewPartitionCreation 1234567def onNewPartitionCreation(newPartitions: Set[TopicAndPartition]) &#123; info(\"New partition creation callback for %s\".format(newPartitions.mkString(\",\"))) partitionStateMachine.handleStateChanges(newPartitions, NewPartition) replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), NewReplica) partitionStateMachine.handleStateChanges(newPartitions, OnlinePartition, offlinePartitionSelector) replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), OnlineReplica)&#125; 创建新增分区对象，分区状态机将新创建分区转变为NewPartition状态 从Controller缓存中取出新增分区的副本分配方案，针对每一个replica进行NonExistentReplica–&gt; NewReplica状态转换 分区状态 NewPartition–&gt;OnlinePartition，调用initializeLeaderAndIsrForPartition(topicAndPartition)为新分区初始化leader和isr路径。主要策略就是让AR中第一个replica作为leader，所有可用的replica作为ISR，将leader、ISR、leaderepoch、controllerepoch、zkversion等信息写入Zk state节点，ControllerContext更新相应topic分区的leader和ISR缓存。之后就是发送LeaderAndIsrRequest给每个replica和UpdateMetadataRequest请求给每个可用的broker 设置副本状态机状态NewReplica—&gt;OnlineReplica，将当前的replica加入到controllerContext AR缓存中。完事…… Broker Failure下面来分析一下某台broker宕机的情况。 broker宕机后，zk会话超时，/brokers/ids对应结点被删除，触发BrokerChangeListener.handleChildChange，接着又调用controller.onBrokerFailure方法， 对Leader副本在deadBroker上的分区（同时要排除topic在删除的状态）触发OfflinePartition状态转换 这一步就是为处于OfflinePartition状态的分区触发OnlinePartition状态转换，ok，还记得上面提到的OfflinePartitionLeaderSelector选举器吧，这回就用它来进行Leader选举、ISR重分配，以及选出接收LeaderAndIsr请求的replica。更新一下Zk state结点的leader和ISR相关信息，更新controllerContext的leader缓存，给相应broker发送LeaderAndIsrRequest请求，顺带发送UpdateMetadataRequest请求，这些动作都是在electLeaderForPartition函数中完成 找出deadBroker上的所有副本，并且要过滤掉一些topics正在执行删除操作的replica，副本状态机执行OfflineRelica状态转换，过程不再赘述 check出正在执行topic删除期间的replica，将这些replica置为ReplicaDeletionIneligible，这些replica在broker down的时候是不能被删除的。 分区副本重新分配策略Kafka提供了分区重新分配的工具，在生产环境下，随着负载的增大，可能需要给Kafka集群扩容，但是对于已存在的topic，并不会自动将分区的副本迁移到新的Broker上，就可以用到这个工具。除此之外，我们还可以用这个工具来调整分区的AR数量，下面就来说一下Partition方案重新分配的情况，也涉及Controller非常重要的一个方法：onPartitionReassignment。当用命令行发起分区重分配操作时，它会在/admin/reassign_partitions路径下创建节点，进而触发PartitionsReassignedListener监听器，执行handleDataChange函数，过滤掉正在执行重分配的副本的分区，接着判断它们的topic是否正在进行删除，构造一个ReassignedPartitionsContext传递给controller.initiateReassignReplicasForTopicPartition为给定topic分区重新分配副本，这个函数的逻辑看了下源码，基本流程如下： 取出controllerContext针对这个分区的AR缓存，当前AR和RAR集合完全一样的的话，抛异常，不用重分配了 否则，判断一下RAR中是否存在不可用的副本，如果存在replica not alive，抛异常，此次重分配操作无法进行 如果RAR中均可用，注册Zk state结点的listen，监听ISR变化，mark一下该topic不能被删除。 最后一步调用最重要的函数onPartitionReassignment开始重新分配分区的副本 onPartitionReassignment这里我们还是以源码中的例子来说明整个流程:OAR = {1,2,3}RAR = (4,5,6) AR(Zk) leader/isr(Zk) transition {1,2,3} 1/{1,2,3} (initial state) {1,2,3,4,5,6} 1/{1,2,3} (step 2) {1,2,3,4,5,6} 1/{1,2,3,4,5,6} (step 4) {1,2,3,4,5,6} 4/{1,2,3,4,5,6} (step 7) {1,2,3,4,5,6} 4/{4,5,6} (step 8) {4,5,6} 4/{4,5,6} (step 10) 总结本文只举了三个经典的例子，后面再慢慢扩充用到Controller的实例分析吧。对于之前连Scala语法都没接触过的老王来说，整个调研学习过程真可谓折磨蛋疼额，技术无止境，共勉吧。However，还是希望本文能对读者有所帮助。 参考文献 官方wiki：Kafka Controller Internals 推荐Kafka相关博客 Kafka Controller源码分析","categories":[{"name":"技术","slug":"技术","permalink":"https://geminiguy.github.io/categories/技术/"}],"tags":[{"name":"Kafka Controller","slug":"Kafka-Controller","permalink":"https://geminiguy.github.io/tags/Kafka-Controller/"},{"name":"源码分析","slug":"源码分析","permalink":"https://geminiguy.github.io/tags/源码分析/"},{"name":"Kafka","slug":"Kafka","permalink":"https://geminiguy.github.io/tags/Kafka/"}]},{"title":"Hello World","slug":"index","date":"2016-12-31T16:00:00.000Z","updated":"2017-01-14T09:27:00.000Z","comments":true,"path":"2017/01/01/index/","link":"","permalink":"https://geminiguy.github.io/2017/01/01/index/","excerpt":"","text":"Hello world，隔壁老王新的一年博客开张个人比较懒，平时知识点也只是随手记录在印象笔记希望这一年能多写一些技术文章吧Whatever，新年快乐Ps：Hexo的环境配置真是好多坑啊，还是比较喜欢NexT这个主题","categories":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/categories/闲聊/"}],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"https://geminiguy.github.io/tags/闲聊/"}]}]}